\documentclass[conference,a4paper]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
%Template version as of 6/27/2024

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}

\usepackage{textcomp}
\usepackage{tikz}
\usepackage{booktabs}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{bookmark}
\usepackage{array}
\usepackage{tabularx}
\usepackage{amssymb} 


\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

% Custom figure command: pass filename and caption
\newcommand{\cfigure}[2]{%
  \begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{figures/#1.png}%
    \caption{#2}%
    \label{fig:#1}%
  \end{figure}%

}
\title{AI for disaster detection and response using satellite imagery}

\author{Dwayne Mark Acosta (300665276) \\ Mohamed Amine Benaziza (300684553) \\ David Franz (300360491) \\ Ray Marange (300671115) \\ James Thompson (300680096)\\
\textit{Victoria University of Wellington}\\}
\date{\today}

\maketitle

\section{Introduction}

% Introduce this paper, It is a summary of ai disaster detection and problems using 5 primary papers (but hopefully more) ...
%% introduce the what remote sensing is
%% tell some statistics about how disaster are bad and increasing (the papers have lots of references)
%% more or less show that there is a great opportunity and need for better disaster response

When disasters strike a rapid and effective response is critical to mitigate their impact on affect communities . Understanding the disaster is essential for coordinating an effective response. Most methods of understanding a disaster rely on ground based data collection which can be slow, dangerous and limited in scope \cite{nhess-21-1431-2021}. Remote sensing is the process of collecting data from a distance, often using satellites or aircraft. A challenge of using remote sensing is that the scale of data is that manual processing is too expensive and slow. By using AI to analyze remote sensing data we can automate the process of extracting useful information from the data. This paper will review the current state of the art in using AI for disaster detection and response.

We will look at how important it is to have effective disaster response and the what can happen as AI is used in the disaster response process. Then we will discuss different applications of AI and remote sensing for disaster response. Specifically the applications of classifying damaged buildings \cite{kimDisasterAssessmentUsing2022,teohExploringGenerativeAI2024,lagapEnhancingPostDisasterDamage2025} and detecting wildfires \cite{elbohy2025fusion,jiaoForestFirePatterns2023}. Lastly we will discuss the challenges of using AI for disaster response and some attempts or methods to overcome these challenges. The challenges mainly fall into two categories data availability and compute constraints.


\section{IMPLICATION OF EFFECTIVE OR INEFFECTIVE DISASTER RESPONSE}
Artificial intelligence has the potential to transform disaster response by accelerating decision-making, improving situational awareness, and optimizing resource allocation. However, the effectiveness of these systems is not solely technical it is deeply intertwined with social equity, data accessibility, and contextual relevance. The selected papers illustrate both the promise and the risks of AI-driven disaster management, especially when deployed in communities with limited infrastructure or socioeconomic vulnerability.
\subsection{DISASTER ASSESSMENT USING COMPUTER VISION AND SATELLITE IMAGERY}
\subsubsection{Effective response}
Rapid quantification of structural damage enables targeted aid delivery to the most affected zones, reducing recovery time and minimizing resource waste.
\subsubsection{Ineffective response}
Misclassification or omission of damage—especially in informal settlements or low-visibility regions—can result in inequitable aid distribution, leaving vulnerable populations underserved.
\subsection{EXPLORING GENERATIVE AI FOR YOLO-BASED OBJECT DETECTION}
\subsubsection{Effective response}
Generative augmentation addresses data scarcity, allowing object detection models to generalize across novel disaster zones and support real-time situational awareness.
\subsubsection{Ineffective response}
Over-reliance on synthetic data without validation may produce brittle models that fail in diverse real-world contexts, particularly in regions lacking annotated datasets.
\subsection{FUSION OF CNN AND TRANSFORMER ARCHITECTURES FOR PROACTIVE WILDFIRE DETECTION}
\subsubsection{Effective response}
Hybrid ConvNeXt-Transformer models enable early wildfire detection, facilitating timely evacuations and reducing environmental and human impact.
\subsubsection{Ineffective response}
Delayed alerts due to poor integration or regional blind spots can allow fires to escalate before responders mobilize, especially in remote or underserved areas.
\subsection{[ENHANCING POST-DISASTER DAMAGE DETECTION WITH ESRGAN}
\subsubsection{Effective response}
Super-resolution and explainability tools (e.g., Grad-CAM++) enhance technical accuracy and build trust among decision-makers, supporting both immediate response and long-term recovery.
\subsubsection{Ineffective response}
Neglecting image quality and interpretability risks biased assessments, particularly in low-income regions where infrastructure may be harder to detect or classify.
\subsection{FOREST FIRE PATTERNS AND LIGHTNING-CAUSED DETECTION IN CHINA}
\subsubsection{Effective response}
Regional pattern analysis ensures models are trained with ecological and geographic awareness, improving accuracy and cultural relevance in intervention strategies.
\subsubsection{Ineffective response}
Generic models that ignore local data may misrepresent fire regimes, leading to interventions that are misaligned with actual community needs.
\subsection{SYNTHESIS}
Together, these studies reveal that effective disaster response systems must go beyond technical precision. They must be:
\begin{itemize}
    \item \textbf{Timely} — enabling early detection and rapid mobilization.
    \item \textbf{Accurate} — leveraging augmentation, super-resolution, and hybrid architectures.
    \item \textbf{Trustworthy} — incorporating explainability and stakeholder confidence.
    \item \textbf{Context-aware} — integrating socioeconomic and regional data.
    \item \textbf{Equity-driven} — ensuring vulnerable populations are not excluded due to data gaps.
\end{itemize}
AI systems that align with these principles can mitigate not amplify existing inequalities. Conversely, systems that ignore socioeconomic context risk turning technological interventions into liabilities, reinforcing disparities in aid, recovery, and resilience.


\section{Application of remote sensing in disaster response}

% This is the results section where we can describe the different application and some basic stats to show how well it can or cannot work (like in chinese mountain range paper)
% How we can use it to detect and classify damaged buildings (~3 paper examples)
% How we can use it for fire detection (2 paper examples)
% How we can use it for more general disaster detection (1 paper example)

Artificial intelligence techniques excel at finding complex non linear patterns in complex data which is otherwise differentiable from noise to humans or other pattern recognition tooling. It is not a huge surprise that AI then is capable of excelling at finding complex patterns in a huge variety of data leading to significant improvements over the previous state of art in a variety of areas (such as fast detection of wildfires, flash flooding, and risky icebergs in shipping routes). This has proven to be highly useful in the area of disaster detection due to being able to get meaningful results from combined many different sources of sensor data rather than any single detection source which may fail under particular circumstances (such as cloud cover preventing detection of wildfires).


\subsection{Wildfires}

Wildfire detection is an example of disaster detection where AI has been used since the 1990s. The authors of the paper begin with a review of ways various types of remote sensing data have led to improvements in rapid response systems. Over time, researchers have explored increasingly more complex data signal sources- from one dimensional inputs such as thermometers, to using increasingly higher resolution satellite cloud data, to complex sensing tools which have high dimensional outputs (which can be helpful where, for example, clouds might block the forests from view of the satellite imagery). This issue of cloud cover blocking data is a big problem, with systems entirely reliant on computer vision techniques only correctly detecting fires on historical satellite data in 30\% of cases.

In general, the quality of output system is dependent both on having high quality data, and designing systems to fully take advantage of the data that you do have. With this in mind, the paper sets out the goal of combining the strengths of computer vision techniques and transformer inspired mechanisms for more comprehensive analysis of wildfire patterns in a ConvNeXt-based architecture. This is able to combine many different sources of sensor data and extract meaningful patterns. The model is carefully designed to trade of computational complexity and accuracy, and many different model variations were released for different hardware types and use cases (ranging from super computer to in field local models).

\begin{quote}
\textit{"ConvNeXt was selected over traditional CNNs such as ResNet and pure transformer-based models like Vision Transformers (ViT) due to its balanced advantages. It achieves superior performance on vision tasks compared to ResNet, while offering efficient training. Unlike ViTs, which generally require very large datasets to perform well, ConvNeXt demands less data, making it better suited for moderately sized datasets."}
\end{quote}
\cite{elbohy2025fusion}


\subsection{Flooding}

Flooding is the most frequent natural disaster causing widespread loss of life and destruction of property. Some flooding will develop slowly, but the most dangerous kind (flash floods) can develop very quickly, leaving minimal time to evacuate or otherwise prepare. This is an area then where small improvements can translate to significant reduction of casualties. Certain geographic areas which experience wet seasons are particularly susceptible to this danger- the paper focuses primarily on Malaysia, (which accounts for 60\% of it's total occurrences of natural disasters), but mentions that globally 1.81 billion people are exposed to flood risk. Beyond the human impact, flooding can have a significant effect on the economy of countries.

\begin{quote}
    " In 2021 alone, water-related disaster resulted in economic losses amounting to \$224.2 billion  globally, nearly doubling the annual average of \$117.8 billion recorded from 2001 to 2020. A recent report also predicts that floods alone are expected to erode more than \$2 trillion from the global GDP by 2050."
\end{quote}

\subsubsection{Detection of flash floods}

Like wildfire detection, statistical analysis and machine learning has been applied to try to improve detection of floods for some time. Traditional methods have focused on hydrological data and satellite observations but have had limitation such as temporal and spatial resolution as well as accuracy performance. Satellite (like Landsat and MODIS) imagery is massively negatively hindered by cloud cover, a slightly ironic limitation given the source of flooding would generally imply high cloud coverage. Other methods such as radar have other benefits for detecting water bodies, mapping flood extents, and tracking changes in land cover.

\subsubsection{YOLO Approach}

The paper tries an approach of building a computer vision based classifier using a dataset of 3750 images collected from various generative AI tools, which were then preprocessed to get a final dataset of 6374 images of flood scenarios. The prompts used to specify the images included specifying the expected country (Malaysia) and specified the angles they knew they would need for the classifier. This is a uniquely low cost method of gathering a comprehensive dataset. In the context of Malaysia, rural areas are more highly effected by flash flooding, and in general flooding has a higher impact on areas with higher poverty. Such a low cost method of gathering data would be particularly valuable to higher poverty areas.

The final results are good, but not beating the state of the art with a mAP of 0.79 and F1-score of 90.8 (in comparison to Mask-R-CNN achieving mAP of 0.95 and F1-score of 97). The uniquely low cost way of building the dataset combined with fairly strong performance do indicate that this is a promising direction to explore, and the paper suggests future research directions which they believe would improve performance further. Particularly in areas of higher poverty, non synthetic datasets may not even exist, so understanding how to get good performance from synthetic data may help reduce inequities associated with this.


\subsection{Other Applications}

\subsubsection{Water Detection}

Another aspect of flood detection is the post flooding stage. The YOLO based model is aims to improve detection of the flood itself, whereas the post flooding stage is based on fixing the problems caused by the flood. This paper builds a classifier using satellite imagery of buildings pre and post flood with simple labels to indicate different sorts of damage.  The paper suggests particular architectural designs leading to their success such as separate encoders developed for pre and post disaster imagery, and also pre training on non disaster satellite imagery. The model achieved strong performances of 91.4\% accuracy.  A model like this is helpful for governments to understand local damage estimates can be especially helpful in prioritizing relief efforts and climate resilient redevelopment.

\subsubsection{Iceberg Detection}

A more commercially focused project was to use artificial intelligence to detect icebergs in northern shipping routes.  Due to the enormous range of weather, lighting, sea,  and the physical conditions of the icebergs themselves, creating a robust classifier for this has proven to be an enormously complex task. The data required is also highly difficult to get and required extensive expert analysis by GIS specialists to be properly labeled. Conversely, such a system would be enormously valuable to the shipping industry, and therefore they are strongly motivated to invest in improving the technology. The final CNN based model is able to encode many features to build a robust classifier performing better than previous methods. This is an example of commercial value driving research directions, but this later leading to humanitarian benefits.


\section{Challenges of using remote sensing for disaster response}


\subsection{TECHNICAL \& DEPLOYMENT CHALLENGES}

\subsubsection{\textbf{Resource-constrained deployment \& real-time processing}}
A major challenge for remote sensing in disaster response is the difficulty of meeting the computational demands of modern machine learning and deep learning models required for real-time processing during critical response phases. While these models often deliver higher performance than lightweight alternatives, deploying them on embedded devices, mobile systems, or Unmanned Aerial Vehicles (UAVs) is hindered by limited processing power, strict energy requirements, and constrained communication bandwidth \cite{elbohy2025fusion}. For instance, flood forecasting systems using Convolutional Neural Networks (CNN) + Modified Particle Swarm Optimization demonstrate high performance but are highly complex and expensive in real-time systems. While CNN-based models like ConvNeXt-Small show promise for wildfire detection, achieving 99.05\% test accuracy, they still lack practical deployment strategies for real-world alert systems \cite{elbohy2025fusion}. This results in a constant trade-off between achieving high model accuracy and ensuring feasible deployment in post-disaster events.

\subsubsection{\textbf{Model interpretability \& trust issues}}
Deep learning models are frequently criticized as ``black boxes,'' offering limited transparency into decision-making, which is problematic in post-disaster contexts where trust and accountability are essential. Explainable AI methods such as Grad-CAM++ can highlight image regions associated with post-disaster damage, but when models lack robust internal representations, the resulting visualizations often appear scattered or inconsistent and fail to capture the overall structural context. Future research should focus on explainability-driven training strategies such as using attention refinement or uncertainty-aware learning to improve how models allocate attention, so that Grad-CAM outputs highlight meaningful disaster-related features rather than scattered or irrelevant regions \cite{lagapEnhancingPostDisasterDamage2025}.

\subsubsection{\textbf{Cross-event generalization \& class imbalance}}
Remote sensing models often struggle to generalise across disaster types and regions. Systems trained on specific events show significant performance degradation when applied to different disaster contexts, with accuracy falling from 85.9\% in-domain to 80.3\% out-of-domain events \cite{kimDisasterAssessmentUsing2022}. Cross-event testing further highlights this limitation, with F1 scores dropping below 0.5 for disasters such as flooding and tsunamis, where submerged buildings cause severe misclassification errors. These challenges are exacerbated by class imbalance, where critical recovery states such as ``New buildings'' (180 samples) are heavily underrepresented compared to ``Not damaged'' (625 samples), and by systematic data gaps in which submerged or debris-obscured structures are missing from training datasets \cite{lagapEnhancingPostDisasterDamage2025}.


\subsection{DATA ACQUISITION \& QUALITY CHALLENGES}

\subsubsection{\textbf{Cost, accessibility \& temporal constraints}}
Access to high-resolution satellite data is often expensive, difficult to acquire in real-time, or subject to cloud cover and operational delays \cite{lagapEnhancingPostDisasterDamage2025}. Due to the fixed temporal resolution of satellites, obtaining images immediately before and after disasters presents significant challenges, while higher-resolution satellites such as Landsat and Sentinel have longer revisit cycles that do not meet timeliness requirements for disaster response. The concentration of high-quality ground-truth data in developed countries also disadvantages disaster-prone developing countries that lack the statistical capacity and resources to produce quality local damage data for training effective models \cite{kimDisasterAssessmentUsing2022}.

\subsubsection{\textbf{Atmospheric \& environmental limitations}}
Disasters themselves often reduce the effectiveness of remote sensing. Cloud cover, smoke, and atmospheric disturbances can obscure satellite views during critical periods \cite{lagapEnhancingPostDisasterDamage2025}. In Heilongjiang Province between 2013 and 2020, the VIIRS satellite detected only 14.8\% of 298 forest fires caused by lightning strikes, with cloud cover and satellite transit timing preventing observation of the remaining 85.2\% \cite{jiaoForestFirePatterns2023}. Dense urban environments and debris further limit the effectiveness of optical imagery \cite{lagapEnhancingPostDisasterDamage2025}, while floods often coincide with heavy cloud cover that obstructs systems such as Landsat and MODIS \cite{teohExploringGenerativeAI2024}. These conditions underscore a critical challenge that disasters frequently occur under circumstances that compromise the very sensing capabilities needed for effective response.


\subsection{OPERATIONAL \& METHODOLOGICAL CHALLENGES}

\subsubsection{\textbf{Multi-temporal analysis \& recovery discrimination}}
Effective post-disaster assessment requires tracking structural changes across three key periods: pre-disaster, event, and post-disaster. Distinguishing between damage, recovery, and new construction over time demands more advanced feature extraction, but current models still misclassify partially damaged, unrepaired, and recovered structures. Most research still focuses on single-timeframe classification, limiting longitudinal recovery analysis. The challenge is compounded by the need to separate damage-specific features from seasonal changes and urban development between image acquisitions \cite{kimDisasterAssessmentUsing2022}. While models such as Vision Transformers (ViT) can compare all three temporal frames given high-resolution imagery, this temporal reasoning remains inconsistent across damage categories \cite{lagapEnhancingPostDisasterDamage2025}.

\subsubsection{\textbf{Synthetic data \& training limitations}}
Synthetic imagery has been explored to address data scarcity, class imbalance, and scenario diversity in disaster response modeling. While effective for augmenting rare classes, achieving mAP50 scores of 96.7\% and F1 scores of 90.8\% in flood detection \cite{teohExploringGenerativeAI2024}, generated data often lacks realism and requires systematic filtering to remove artifacts such as cartoon-like imagery. Current approaches also face restrictions on the volume of data AI tools can generate and the need for carefully designed prompts to reduce bias. Lastly, synthetic datasets cannot capture the complex physical and spatial dynamics of real disasters, struggling to replicate environmental interactions and temporal dynamics across pre-disaster, event, and post-disaster stages.


\section{Conclusion}
Across six complementary studies, remote sensing emerges as central to disaster response: it delivers fast situation awareness from satellites and drones, but impact is limited by observability, domain shift, and label constraints.

Empirically, the papers span fires, floods, sea-ice hazards, and built-environment damage. In Heilongjiang, satellites track seasonal fire trends but miss many lightning ignitions because of clouds and revisit timing: lightning causes 77.6\% of fires, yet under 30\% of all fires are detected by VIIRS (Visible Infrared Imaging Radiometer Suite) and under 15\% of lightning fires, and the monitorable fraction falls as lightning’s share rises ($r=-0.888$, $p=0.003$). When satellites do see events they typically \emph{precede} ground reports by about 1--8 hours, showing real early-warning value. For building damage, a lightweight pseudo-siamese grid classifier reaches about 91\% accuracy in-domain and about 80\% out-of-domain, and remains usable on new crises (Providencia: 97.5\% accuracy, $F_1=0.851$) despite coarse labels. For flood response, YOLOv8 trained on generative synthetic imagery attains $\text{mAP}_{50}=0.967$, $\text{mAP}_{[0.5,0.95]}=0.787$, and $F_1=0.908$, while tests on real drone scenes reveal transfer brittleness that argues for standardized capture and curation. For wildfires, a ConvNeXt-Small hybrid (CNN+Transformer) delivers about 99.05\% test accuracy on satellite tiles. In polar waters, fusing RCM SAR with ViT features, simple statistics, and ERA5 winds enables four-way classification (open water, sea ice, and each “with iceberg”) at 96.5\% accuracy with roughly 1\% false alarms; collapsing to target vs.\ no-target yields 98.9\%. Finally, enhanced super-resolution GANs (ESRGAN) directly target small objects and minority classes, improving recall where post-disaster monitoring needs it most.

\textbf{Current challenges.} Common issues recur across hazards and sensors:
\begin{itemize}
  \item \textit{Observability gaps:} cloud or smoke occlusion, night/illumination limits for optical, and revisit latency (e.g., May--July lightning fires in the Daxing’an Mountains).
  \item \textit{Domain shift:} synthetic$\rightarrow$real, drone$\rightarrow$satellite, region$\rightarrow$region can erode field performance despite strong lab metrics.
  \item \textit{Label scarcity and imbalance:} rare but critical classes (destroyed buildings, small icebergs, early fire pixels) and coarse/incomplete labels bias training and evaluation.
  \item \textit{Sensor heterogeneity:} mixing optical, SAR, thermal, UAV, and reanalyses requires careful calibration, metadata discipline, and uncertainty handling.
  \item \textit{Deployment constraints:} bandwidth, power, and the need for robust, on-edge inference under adverse weather and communications.
\end{itemize}

\textbf{Future directions.} The line of work across these papers points to end-to-end, field-robust pipelines:
\begin{enumerate}
  \item \textit{Task-to-action frameworks:} operationalize concepts like FloodIntel (tasking$\rightarrow$standardized capture$\rightarrow$multi-modal fusion$\rightarrow$prioritized dispatch) with auditable decisions and latency budgets.
  \item \textit{Smaller, faster models at the edge:} distill/quantize strong backbones (ConvNeXt-S, YOLOv8n/s/m) for drones, field laptops, and small satellites, with calibrated uncertainty.
  \item \textit{Richer fusion:} couple SAR+optical+thermal+UAV with environmental context (e.g., ERA5 winds) to separate look-alikes (open water vs.\ sea ice) and operate through clouds/smoke.
  \item \textit{Label-efficient learning:} self-supervision, weak/active learning, and ESRGAN super-resolution to raise recall on minority classes with limited ground truth.
  \item \textit{Data and protocol standardization:} define drone flight profiles, view angles, ground sampling distance, and annotation rubrics so synthetic and real images match at train and test time.
  \item \textit{Fair, reliable evaluation:} report imbalance-aware metrics, out-of-domain tests, occlusion stress tests, and end-to-end latency, not only headline mAP or accuracy.
\end{enumerate}

In sum, remote sensing already yields earlier wildfire alerts, faster flood triage, and safer polar navigation. Realizing its full promise now hinges on standardizing data collection, hardening models against shift, boosting rare-class recall (via ESRGANs and active learning), and embedding compact, trustworthy predictors inside operational workflows for end-to-end disaster response.

\bibliographystyle{IEEEtran}
\bibliography{references}
  
\end{document}
