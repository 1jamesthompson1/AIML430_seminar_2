\documentclass[conference,a4paper]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
%Template version as of 6/27/2024

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}

\usepackage{textcomp}
\usepackage{tikz}
\usepackage{booktabs}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{bookmark}
\usepackage{array}
\usepackage{tabularx}
\usepackage{amssymb} 


\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

% Custom figure command: pass filename and caption
\newcommand{\cfigure}[2]{%
  \begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{figures/#1.png}%
    \caption{#2}%
    \label{fig:#1}%
  \end{figure}%

}
\title{AI for disaster detection and response using satellite imagery}

\author{Dwayne Mark Acosta (300665276) \\ Mohamed Amine Benaziza (300684553) \\ David Franz (300360491) \\ Ray Marange (300671115) \\ James Thompson (300680096)\\
\textit{Victoria University of Wellington}\\}
\date{\today}

\maketitle

\section{Introduction}

% Introduce this paper, It is a summary of ai disaster detection and problems using 5 primary papers (but hopefully more) ...
%% introduce the what remote sensing is
%% tell some statistics about how disaster are bad and increasing (the papers have lots of references)
%% more or less show that there is a great opportunity and need for better disaster response

\cite{elbohy2025fusion} etc...


\section{IMPLICATION OF EFFECTIVE OR INEFFECTIVE DISASTER RESPONSE}


\section{Application of remote sensing in disaster response}

% This is the results section where we can describe the different application and some basic stats to show how well it can or cannot work (like in chinese mountain range paper)
% How we can use it to detect and classify damaged buildings (~3 paper examples)
% How we can use it for fire detection (2 paper examples)
% How we can use it for more general disaster detection (1 paper example)

\section{Challenges of using remote sensing for disaster response}


\subsection{TECHNICAL \& DEPLOYMENT CHALLENGES}

\subsubsection{\textbf{Resource-constrained deployment \& real-time processing}}
A major challenge for remote sensing in disaster response is the difficulty of meeting the computational demands of modern machine learning and deep learning models required for real-time processing during critical response phases. While these models often deliver higher performance than lightweight alternatives, deploying them on embedded devices, mobile systems, or Unmanned Aerial Vehicles (UAVs) is hindered by limited processing power, strict energy requirements, and constrained communication bandwidth \cite{elbohy2025fusion}. For instance, Padmawar et al.'s flood forecasting system using Convolutional Neural Networks (CNN) + Modified Particle Swarm Optimization demonstrate high performance but are highly complex and expensive in real-time systems. Similarly, while Elbohy et al.'s ConvNeXt-Small model show promise for wildfire detection, achieving 99.05\% test accuracy on the Wildfire Prediction Dataset, it still lacks practical deployment strategies for real-world alert systems \cite{elbohy2025fusion}. This results in a constant trade-off between achieving high model accuracy and ensuring feasible deployment in post-disaster events.

\subsubsection{\textbf{Model interpretability \& trust issues}}
Deep learning models are frequently criticized as ``black boxes,'' offering limited transparency into decision-making, which is problematic in post-disaster contexts where trust and accountability are essential. Explainable AI methods such as Grad-CAM++ can highlight image regions associated with post-disaster damage, but when models lack robust internal representations, the resulting visualizations often appear scattered or inconsistent and fail to capture the overall structural context. Future research should focus on explainability-driven training strategies such as using attention refinement or uncertainty-aware learning to improve how models allocate attention, so that Grad-CAM outputs highlight meaningful disaster-related features rather than scattered or irrelevant regions \cite{lagapEnhancingPostDisasterDamage2025}.

\subsubsection{\textbf{Cross-event generalization \& class imbalance}}
Kim et al. (2022) investigated the application of computer vision techniques for water-related disaster damage assessment using satellite imagery, they found that remote sensing models often struggle to generalise across disaster types and regions. Systems trained on specific events show significant performance degradation when applied to different disaster contexts, with accuracy falling from 85.9\% in-domain to 80.3\% out-of-domain events \cite{kimDisasterAssessmentUsing2022}. Cross-event testing further highlights this limitation, with F1 scores dropping below 0.5 for disasters such as flooding and tsunamis (Sunda Strait: 0.164, Midwestern Flooding: 0.495). These challenges are exacerbated by class imbalance such as those found in the Philippines post-Typhoon Haiyan dataset where critical recovery states such as ``New buildings'' (180 samples) are heavily underrepresented compared to ``Not damaged'' (625 samples), and by systematic data gaps in which submerged or debris-obscured structures are missing \cite{lagapEnhancingPostDisasterDamage2025}.


\subsection{DATA ACQUISITION \& QUALITY CHALLENGES}

\subsubsection{\textbf{Cost, accessibility \& temporal constraints}}
Access to very high-resolution satellite data is often limited, delayed, or cost-prohibitive due to cloud cover and operational constraints, as Lagap and Ghaffarian found when working with the Tacloban, Philippines post-Typhoon Haiyan dataset. Satellites face an inherent trade-off between spatial and temporal resolutionâ€”higher spatial resolution satellites have longer revisit cycles that cannot meet the timeliness requirements for disaster response, while lower resolution satellites with more frequent coverage lack the spatial detail needed for damage assessment. To address this gap, Lagap and Ghaffarian proposed ESRGAN as a cost-effective solution that enhances readily available low-resolution imagery, improving classification accuracy by approximately 4-5\% for post-disaster damage detection without requiring expensive very high-resolution data sources \cite{lagapEnhancingPostDisasterDamage2025}.

\subsubsection{\textbf{Atmospheric \& environmental limitations}}
Disasters themselves often reduce the effectiveness of remote sensing. Cloud cover, smoke, and atmospheric disturbances can obscure satellite views during critical periods \cite{lagapEnhancingPostDisasterDamage2025}. In Heilongjiang Province between 2013 and 2020, the VIIRS satellite detected only 14.8\% of 298 forest fires caused by lightning strikes, with cloud cover and satellite transit timing preventing observation of the remaining 85.2\% \cite{jiaoForestFirePatterns2023}. Dense urban environments and debris further limit the effectiveness of optical imagery \cite{lagapEnhancingPostDisasterDamage2025}, while floods often coincide with heavy cloud cover that obstructs systems such as Landsat and MODIS \cite{teohExploringGenerativeAI2024}. These conditions underscore a critical challenge that disasters frequently occur under circumstances that compromise the very sensing capabilities needed for effective response.


\subsection{OPERATIONAL \& METHODOLOGICAL CHALLENGES}

\subsubsection{\textbf{Multi-temporal analysis \& recovery discrimination}}
Effective post-disaster assessment requires tracking structural changes across three key periods: pre-disaster, event, and post-disaster. Distinguishing between damage, recovery, and new construction over time demands more advanced feature extraction as current models still misclassify partially damaged, unrepaired, and recovered structures - this is evident in the Tacloban post-Typhoon Haiyan dataset where "Not Recovered" and "Recovered" categories remain particularly challenging to differentiate. The challenge is compounded by the need to separate damage-specific features from seasonal changes and urban development between image acquisitions \cite{kimDisasterAssessmentUsing2022}. While models such as Vision Transformers (ViT) can compare all three temporal frames given high-resolution imagery, this temporal reasoning remains inconsistent across damage categories \cite{lagapEnhancingPostDisasterDamage2025}.

\subsubsection{\textbf{Synthetic data \& training limitations}}
Synthetic imagery has been explored to address data scarcity, class imbalance, and scenario diversity in disaster response modeling. While effective for augmenting rare classes, achieving mAP50 scores of 96.7\% and F1 scores of 90.8\% in flood detection as demonstrated by Teoh et al. using YOLO-based models on Malaysian flood scenarios \cite{teohExploringGenerativeAI2024}, generated data often lacks realism and requires systematic filtering to remove artifacts such as cartoon-like imagery. Current approaches also face restrictions on the volume of data AI tools can generate and the need for carefully designed prompts to reduce bias. Lastly, synthetic datasets cannot capture the complex physical and spatial dynamics of real disasters, struggling to replicate environmental interactions and temporal dynamics across pre-disaster, event, and post-disaster stages.


\section{Conclusion}


\bibliographystyle{IEEEtran}
\bibliography{references}
  
\end{document}
