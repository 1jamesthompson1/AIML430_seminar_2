\documentclass[conference,a4paper]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
%Template version as of 6/27/2024

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}

\usepackage{textcomp}
\usepackage{tikz}
\usepackage{booktabs}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{bookmark}
\usepackage{array}
\usepackage{tabularx}
\usepackage{amssymb} 


\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

% Custom figure command: pass filename and caption
\newcommand{\cfigure}[2]{%
  \begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{figures/#1.png}%
    \caption{#2}%
    \label{fig:#1}%
  \end{figure}%

}
\title{AI for disaster detection and response using satellite imagery}

\author{Dwayne Mark Acosta (300665276) \\ Mohamed Amine Benaziza (300684553) \\ David Franz (300360491) \\ Ray Marange (300671115) \\ James Thompson (300680096)\\
\textit{Victoria University of Wellington}\\}
\date{\today}

\maketitle

\section{Introduction}

% Introduce this paper, It is a summary of ai disaster detection and problems using 5 primary papers (but hopefully more) ...
%% introduce the what remote sensing is
%% tell some statistics about how disaster are bad and increasing (the papers have lots of references)
%% more or less show that there is a great opportunity and need for better disaster response

When disasters strike a rapid and effective response is critical to mitigate their impact on affect communities . Understanding the disaster is essential for coordinating an effective response. Most methods of understanding a disaster rely on ground based data collection which can be slow, dangerous and limited in scope \cite{nhess-21-1431-2021}. Remote sensing is the process of collecting data from a distance, often using satellites or aircraft. A challenge of using remote sensing is that the scale of data is that manual processing is too expensive and slow. By using AI to analyze remote sensing data we can automate the process of extracting useful information from the data. This paper will review the current state of the art in using AI for disaster detection and response.

We will look at how important it is to have effective disaster response and the what can happen as AI is used in the disaster response process. Then we will discuss different applications of AI and remote sensing for disaster response. Specifically the applications of classifying damaged buildings \cite{kimDisasterAssessmentUsing2022,teohExploringGenerativeAI2024,lagapEnhancingPostDisasterDamage2025} and detecting wildfires \cite{elbohy2025fusion,jiaoForestFirePatterns2023}. Lastly we will discuss the challenges of using AI for disaster response and some attempts or methods to overcome these challenges. The challenges mainly fall into two categories data availability and compute constraints.


\section{IMPLICATION OF EFFECTIVE OR INEFFECTIVE DISASTER RESPONSE}
Artificial intelligence has the potential to transform disaster response by accelerating decision-making, improving situational awareness, and optimizing resource allocation. However, the effectiveness of these systems is not solely technical it is deeply intertwined with social equity, data accessibility, and contextual relevance. The selected papers illustrate both the promise and the risks of AI-driven disaster management, especially when deployed in communities with limited infrastructure or socioeconomic vulnerability.
\subsection{DISASTER ASSESSMENT USING COMPUTER VISION AND SATELLITE IMAGERY}
\subsubsection{Effective response}
Rapid quantification of structural damage enables targeted aid delivery to the most affected zones, reducing recovery time and minimizing resource waste.
\subsubsection{Ineffective response}
Misclassification or omission of damage—especially in informal settlements or low-visibility regions—can result in inequitable aid distribution, leaving vulnerable populations underserved.
\subsection{EXPLORING GENERATIVE AI FOR YOLO-BASED OBJECT DETECTION}
\subsubsection{Effective response}
Generative augmentation addresses data scarcity, allowing object detection models to generalize across novel disaster zones and support real-time situational awareness.
\subsubsection{Ineffective response}
Over-reliance on synthetic data without validation may produce brittle models that fail in diverse real-world contexts, particularly in regions lacking annotated datasets.
\subsection{FUSION OF CNN AND TRANSFORMER ARCHITECTURES FOR PROACTIVE WILDFIRE DETECTION}
\subsubsection{Effective response}
Hybrid ConvNeXt-Transformer models enable early wildfire detection, facilitating timely evacuations and reducing environmental and human impact.
\subsubsection{Ineffective response}
Delayed alerts due to poor integration or regional blind spots can allow fires to escalate before responders mobilize, especially in remote or underserved areas.
\subsection{[ENHANCING POST-DISASTER DAMAGE DETECTION WITH ESRGAN}
\subsubsection{Effective response}
Super-resolution and explainability tools (e.g., Grad-CAM++) enhance technical accuracy and build trust among decision-makers, supporting both immediate response and long-term recovery.
\subsubsection{Ineffective response}
Neglecting image quality and interpretability risks biased assessments, particularly in low-income regions where infrastructure may be harder to detect or classify.
\subsection{FOREST FIRE PATTERNS AND LIGHTNING-CAUSED DETECTION IN CHINA}
\subsubsection{Effective response}
Regional pattern analysis ensures models are trained with ecological and geographic awareness, improving accuracy and cultural relevance in intervention strategies.
\subsubsection{Ineffective response}
Generic models that ignore local data may misrepresent fire regimes, leading to interventions that are misaligned with actual community needs.
\subsection{SYNTHESIS}
Together, these studies reveal that effective disaster response systems must go beyond technical precision. They must be:
\begin{itemize}
    \item \textbf{Timely} — enabling early detection and rapid mobilization.
    \item \textbf{Accurate} — leveraging augmentation, super-resolution, and hybrid architectures.
    \item \textbf{Trustworthy} — incorporating explainability and stakeholder confidence.
    \item \textbf{Context-aware} — integrating socioeconomic and regional data.
    \item \textbf{Equity-driven} — ensuring vulnerable populations are not excluded due to data gaps.
\end{itemize}
AI systems that align with these principles can mitigate not amplify existing inequalities. Conversely, systems that ignore socioeconomic context risk turning technological interventions into liabilities, reinforcing disparities in aid, recovery, and resilience.


\section{Application of remote sensing in disaster response}

% This is the results section where we can describe the different application and some basic stats to show how well it can or cannot work (like in chinese mountain range paper)
% How we can use it to detect and classify damaged buildings (~3 paper examples)
% How we can use it for fire detection (2 paper examples)
% How we can use it for more general disaster detection (1 paper example)

AI techniques excel at finding complex non linear patterns in data which is otherwise differentiable from noise to humans or other pattern recognition tooling. It is not a huge surprise that AI then is capable of excelling at finding complex patterns in a huge variety of data leading to massive improvements over the previous state of art in a variety of areas (such as classification of risky icebergs in shipping routes).

\textbf{Example 1- Wildfires}

Wildfire detection is an example of disaster detection where AI has been used since the 1990s. The authors of the paper begin with a review of ways various types of remote sensing data have led to improvements in rapid response systems. 

Over time, researchers have explored increasingly more complex data signal sources- from one dimensional inputs such as thermometers, to using increasingly higher resolution satellite cloud data, to complex sensing tools which have high dimensional outputs (which can be helpful where, for example, clouds might block the forests from view of the satellite imagery). This issue of cloud cover blocking data is quite a big problem for systems entirely reliant on computer vision techniques. 

\textbf{"Matching VIIRS forest fire location data with historical ground forest fire data shows that less than 30\% of forest fires were detected by satellite, and lightning strikes account for less than 15\% of forest fires."}
(Chinese mountain paper)

This shows a common theme in AI in general- that the quality of output system is dependent both on having high quality data, and also  designing systems to fully take advantage of the data that you do have. With this in mind, the paper sets out the goal of combining the strengths of computer vision techniques and transformer inspired mechanisms for more comprehensive analysis of wildfire patterns in a ConvNeXt-based architecture. System values extracting a lot of meaning from less data to build more scalable systems.

\textbf{Algorithm design}
"To reduce computational complexity while effectively capturing both spatial and channel-wise features, depthwise separable convolutions are utilized. Instead of Batch Normalization, Layer Normalization is applied, providing greater stability during training, especially with large datasets. The GELU activation function is employed to improve gradient flow and introduce better non-linearity, resulting in richer feature representations. Furthermore, the use of larger kernel sizes enables improved context aggregation, emulating the global receptive field characteristic of transformers."



\textbf{Example 2- Iceberg classification}

A more commercially focused project was using AI for detecting icebergs in Northern shipping routes. Traditional classifiers have been built on relying on principles which may not be true in all cases (such as icebergs that exhibit higher backscatter than the surrounding water). 

Due to the enormous range of weather, lighting, sea,  and the physical conditions of the icebergs themselves, it has proven to be an enormously complex task to create a robust classifier for this. Conversely, such a system would be enormously valuable to the shipping industry, and therefore they are strongly motivated to invest in improving the technology.

Another note about about this is the example is the complexity of getting good data to begin with. In the one year study, only 102 images in the required format were able to be collected which then all required extensive analysis by GIS specialists and then confirmed with rigorous cross referencing with other data sources. The paper uses this human labeled data to build a CNN model, which performs well compared to the limitations of previous techniques.




\section{Challenges of using remote sensing for disaster response}


\subsection{TECHNICAL \& DEPLOYMENT CHALLENGES}


\subsubsection{\textbf{Resource-constrained deployment \& real-time processing}}
A major challenge for remote sensing in disaster response is the difficulty of meeting the computational demands of modern machine learning and deep learning models required for real-time processing during critical response phases. While these models often deliver higher performance than lightweight alternatives, deploying them on embedded devices, mobile systems, or Unmanned Aerial Vehicles (UAVs) is hindered by limited processing power, strict energy requirements, and constrained communication bandwidth \cite{elbohy2025fusion}. For instance, Padmawar et al.'s flood forecasting system using Convolutional Neural Networks (CNN) + Modified Particle Swarm Optimization demonstrate high performance but are highly complex and expensive in real-time systems. Similarly, while Elbohy et al.'s ConvNeXt-Small model show promise for wildfire detection, achieving 99.05\% test accuracy on the Wildfire Prediction Dataset, it still lacks practical deployment strategies for real-world alert systems \cite{elbohy2025fusion}. This results in a constant trade-off between achieving high model accuracy and ensuring feasible deployment in post-disaster events.

\subsubsection{\textbf{Model interpretability \& trust issues}}
Deep learning models are frequently criticized as ``black boxes,'' offering limited transparency into decision-making, which is problematic in post-disaster contexts where trust and accountability are essential. Explainable AI methods such as Grad-CAM++ can highlight image regions associated with post-disaster damage, but when models lack robust internal representations, the resulting visualizations often appear scattered or inconsistent and fail to capture the overall structural context. Future research should focus on explainability-driven training strategies such as using attention refinement or uncertainty-aware learning to improve how models allocate attention, so that Grad-CAM outputs highlight meaningful disaster-related features rather than scattered or irrelevant regions \cite{lagapEnhancingPostDisasterDamage2025}.

\subsubsection{\textbf{Cross-event generalization \& class imbalance}}
Kim et al. (2022) investigated the application of computer vision techniques for water-related disaster damage assessment using satellite imagery, they found that remote sensing models often struggle to generalise across disaster types and regions. Systems trained on specific events show significant performance degradation when applied to different disaster contexts, with accuracy falling from 85.9\% in-domain to 80.3\% out-of-domain events \cite{kimDisasterAssessmentUsing2022}. Cross-event testing further highlights this limitation, with F1 scores dropping below 0.5 for disasters such as flooding and tsunamis (Sunda Strait: 0.164, Midwestern Flooding: 0.495). These challenges are exacerbated by class imbalance such as those found in the Philippines post-Typhoon Haiyan dataset where critical recovery states such as ``New buildings'' (180 samples) are heavily underrepresented compared to ``Not damaged'' (625 samples), and by systematic data gaps in which submerged or debris-obscured structures are missing \cite{lagapEnhancingPostDisasterDamage2025}.


\subsection{DATA ACQUISITION \& QUALITY CHALLENGES}

\subsubsection{\textbf{Cost, accessibility \& temporal constraints}}
Access to very high-resolution satellite data is often limited, delayed, or cost-prohibitive due to cloud cover and operational constraints, as Lagap and Ghaffarian found when working with the Tacloban, Philippines post-Typhoon Haiyan dataset. Satellites face an inherent trade-off between spatial and temporal resolution—higher spatial resolution satellites have longer revisit cycles that cannot meet the timeliness requirements for disaster response, while lower resolution satellites with more frequent coverage lack the spatial detail needed for damage assessment. To address this gap, Lagap and Ghaffarian proposed ESRGAN as a cost-effective solution that enhances readily available low-resolution imagery, improving classification accuracy by approximately 4-5\% for post-disaster damage detection without requiring expensive very high-resolution data sources \cite{lagapEnhancingPostDisasterDamage2025}.

\subsubsection{\textbf{Atmospheric \& environmental limitations}}
Disasters themselves often reduce the effectiveness of remote sensing. Cloud cover, smoke, and atmospheric disturbances can obscure satellite views during critical periods \cite{lagapEnhancingPostDisasterDamage2025}. In Heilongjiang Province between 2013 and 2020, the VIIRS satellite detected only 14.8\% of 298 forest fires caused by lightning strikes, with cloud cover and satellite transit timing preventing observation of the remaining 85.2\% \cite{jiaoForestFirePatterns2023}. Dense urban environments and debris further limit the effectiveness of optical imagery \cite{lagapEnhancingPostDisasterDamage2025}, while floods often coincide with heavy cloud cover that obstructs systems such as Landsat and MODIS \cite{teohExploringGenerativeAI2024}. These conditions underscore a critical challenge that disasters frequently occur under circumstances that compromise the very sensing capabilities needed for effective response.


\subsection{OPERATIONAL \& METHODOLOGICAL CHALLENGES}

\subsubsection{\textbf{Multi-temporal analysis \& recovery discrimination}}
Effective post-disaster assessment requires tracking structural changes across three key periods: pre-disaster, event, and post-disaster. Distinguishing between damage, recovery, and new construction over time demands more advanced feature extraction as current models still misclassify partially damaged, unrepaired, and recovered structures - this is evident in the Tacloban post-Typhoon Haiyan dataset where "Not Recovered" and "Recovered" categories remain particularly challenging to differentiate. The challenge is compounded by the need to separate damage-specific features from seasonal changes and urban development between image acquisitions \cite{kimDisasterAssessmentUsing2022}. While models such as Vision Transformers (ViT) can compare all three temporal frames given high-resolution imagery, this temporal reasoning remains inconsistent across damage categories \cite{lagapEnhancingPostDisasterDamage2025}.

\subsubsection{\textbf{Synthetic data \& training limitations}}
Synthetic imagery has been explored to address data scarcity, class imbalance, and scenario diversity in disaster response modeling. While effective for augmenting rare classes, achieving mAP50 scores of 96.7\% and F1 scores of 90.8\% in flood detection as demonstrated by Teoh et al. using YOLO-based models on Malaysian flood scenarios \cite{teohExploringGenerativeAI2024}, generated data often lacks realism and requires systematic filtering to remove artifacts such as cartoon-like imagery. Current approaches also face restrictions on the volume of data AI tools can generate and the need for carefully designed prompts to reduce bias. Lastly, synthetic datasets cannot capture the complex physical and spatial dynamics of real disasters, struggling to replicate environmental interactions and temporal dynamics across pre-disaster, event, and post-disaster stages.


\section{Conclusion}
Across six complementary studies, remote sensing emerges as central to disaster response: it delivers fast situation awareness from satellites and drones, but impact is limited by observability, domain shift, and label constraints.

Empirically, the papers span fires, floods, sea-ice hazards, and built-environment damage. In Heilongjiang, satellites track seasonal fire trends but miss many lightning ignitions because of clouds and revisit timing: lightning causes 77.6\% of fires, yet under 30\% of all fires are detected by VIIRS (Visible Infrared Imaging Radiometer Suite) and under 15\% of lightning fires, and the monitorable fraction falls as lightning’s share rises ($r=-0.888$, $p=0.003$). When satellites do see events they typically \emph{precede} ground reports by about 1--8 hours, showing real early-warning value. For building damage, a lightweight pseudo-siamese grid classifier reaches about 91\% accuracy in-domain and about 80\% out-of-domain, and remains usable on new crises (Providencia: 97.5\% accuracy, $F_1=0.851$) despite coarse labels. For flood response, YOLOv8 trained on generative synthetic imagery attains $\text{mAP}_{50}=0.967$, $\text{mAP}_{[0.5,0.95]}=0.787$, and $F_1=0.908$, while tests on real drone scenes reveal transfer brittleness that argues for standardized capture and curation. For wildfires, a ConvNeXt-Small hybrid (CNN+Transformer) delivers about 99.05\% test accuracy on satellite tiles. In polar waters, fusing RCM SAR with ViT features, simple statistics, and ERA5 winds enables four-way classification (open water, sea ice, and each “with iceberg”) at 96.5\% accuracy with roughly 1\% false alarms; collapsing to target vs.\ no-target yields 98.9\%. Finally, enhanced super-resolution GANs (ESRGAN) directly target small objects and minority classes, improving recall where post-disaster monitoring needs it most.

\textbf{Current challenges.} Common issues recur across hazards and sensors:
\begin{itemize}
  \item \textit{Observability gaps:} cloud or smoke occlusion, night/illumination limits for optical, and revisit latency (e.g., May--July lightning fires in the Daxing’an Mountains).
  \item \textit{Domain shift:} synthetic$\rightarrow$real, drone$\rightarrow$satellite, region$\rightarrow$region can erode field performance despite strong lab metrics.
  \item \textit{Label scarcity and imbalance:} rare but critical classes (destroyed buildings, small icebergs, early fire pixels) and coarse/incomplete labels bias training and evaluation.
  \item \textit{Sensor heterogeneity:} mixing optical, SAR, thermal, UAV, and reanalyses requires careful calibration, metadata discipline, and uncertainty handling.
  \item \textit{Deployment constraints:} bandwidth, power, and the need for robust, on-edge inference under adverse weather and communications.
\end{itemize}

\textbf{Future directions.} The line of work across these papers points to end-to-end, field-robust pipelines:
\begin{enumerate}
  \item \textit{Task-to-action frameworks:} operationalize concepts like FloodIntel (tasking$\rightarrow$standardized capture$\rightarrow$multi-modal fusion$\rightarrow$prioritized dispatch) with auditable decisions and latency budgets.
  \item \textit{Smaller, faster models at the edge:} distill/quantize strong backbones (ConvNeXt-S, YOLOv8n/s/m) for drones, field laptops, and small satellites, with calibrated uncertainty.
  \item \textit{Richer fusion:} couple SAR+optical+thermal+UAV with environmental context (e.g., ERA5 winds) to separate look-alikes (open water vs.\ sea ice) and operate through clouds/smoke.
  \item \textit{Label-efficient learning:} self-supervision, weak/active learning, and ESRGAN super-resolution to raise recall on minority classes with limited ground truth.
  \item \textit{Data and protocol standardization:} define drone flight profiles, view angles, ground sampling distance, and annotation rubrics so synthetic and real images match at train and test time.
  \item \textit{Fair, reliable evaluation:} report imbalance-aware metrics, out-of-domain tests, occlusion stress tests, and end-to-end latency, not only headline mAP or accuracy.
\end{enumerate}

In sum, remote sensing already yields earlier wildfire alerts, faster flood triage, and safer polar navigation. Realizing its full promise now hinges on standardizing data collection, hardening models against shift, boosting rare-class recall (via ESRGANs and active learning), and embedding compact, trustworthy predictors inside operational workflows for end-to-end disaster response.

\bibliographystyle{IEEEtran}
\bibliography{references}
  
\end{document}
