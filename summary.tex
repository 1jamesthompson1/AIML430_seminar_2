\documentclass[conference,a4paper]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
%Template version as of 6/27/2024

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}

\usepackage{textcomp}
\usepackage{tikz}
\usepackage{booktabs}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{bookmark}
\usepackage{array}
\usepackage{tabularx}
\usepackage{amssymb} 


\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

% Custom figure command: pass filename and caption
\newcommand{\cfigure}[2]{%
  \begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{figures/#1.png}%
    \caption{#2}%
    \label{fig:#1}%
  \end{figure}%

}
\title{AI for disaster detection and response using satellite imagery}

\author{Dwayne Mark Acosta (300665276) \\ Mohamed Amine Benaziza (300684553) \\ David Franz (300360491) \\ Ray Marange (300671115) \\ James Thompson (300680096)\\
\textit{Victoria University of Wellington}\\}
\date{\today}

\maketitle

\section{Introduction}

% Introduce this paper, It is a summary of ai disaster detection and problems using 5 primary papers (but hopefully more) ...
%% introduce the what remote sensing is
%% tell some statistics about how disaster are bad and increasing (the papers have lots of references)
%% more or less show that there is a great opportunity and need for better disaster response

When disasters strike, a rapid and effective response is critical to mitigate their impact on affected communities. Understanding the disaster is essential for coordinating an rapid and effective response. Most methods of understanding a disaster rely on ground based data collection which can be slow, dangerous and limited in scope \cite{nhess-21-1431-2021}. Remote sensing is the process of collecting data from a distance, often using satellites or aircraft. The vast scale of remote sensing data makes manual processing prohibitively slow and expensive. By using AI to analyze remote sensing data we can automate the process of extracting useful information from the data. This paper will review the current state of the art in using AI for disaster detection and response.

We will look at how important it is to have effective disaster response and the what can happen as AI is used in the disaster response process. Then we will discuss different applications of AI and remote sensing for disaster response, specifically the applications of classifying damaged buildings \cite{kimDisasterAssessmentUsing2022,teohExploringGenerativeAI2024,lagapEnhancingPostDisasterDamage2025} and detecting wildfires \cite{elbohy2025fusion,jiaoForestFirePatterns2023}. Lastly we will discuss the challenges of using AI for disaster response and some attempts or methods to overcome these challenges. The challenges mainly fall into two categories data availability and compute constraints.

\section{Implication of Effective or Ineffective Disaster Response}

Artificial intelligence has the potential to transform disaster response by accelerating decision-making, improving situational awareness, and optimizing resource allocation. However, the effectiveness of these systems is not solely technical; it is deeply intertwined with social equity, data accessibility, and contextual relevance. The selected papers illustrate both the promise and the risks of AI-driven disaster management, especially when deployed in communities with limited infrastructure or socioeconomic vulnerability.

\subsection{CRITICAL FINDINGS BY STUDY}

\subsubsection{Disaster Assessment using Computer Vision and Satellite Imagery}
An effective AI system can rapidly quantify structural damage, enabling targeted aid delivery to the most affected zones, which reduces recovery time and minimizes resource waste. Conversely, an ineffective system risks misclassifying or omitting damage, especially in informal settlements which can result in inequitable aid distribution and leave vulnerable populations underserved.

\subsubsection{Exploring Generative AI for YOLO-Based Object Detection}
The use of generative AI for data augmentation can effectively address data scarcity, allowing models to generalize across novel disaster zones and support real-time situational awareness. However, an over-reliance on unvalidated synthetic data may produce brittle models that fail in diverse real-world contexts, particularly in regions that lack local annotated datasets for validation.

\subsubsection{Fusion of CNN and Transformer Architectures for Proactive Wildfire Detection}
A hybrid ConvNeXt-Transformer model can enable early wildfire detection, facilitating timely evacuations and reducing environmental and human impact. Ineffectiveness arises from delayed alerts due to poor system integration or regional blind spots, which can allow fires to escalate uncontrollably before responders can mobilize, especially in remote areas.

\subsubsection{Enhancing Post-Disaster Damage Detection with ESRGAN}
Effective systems use super-resolution and explainability tools like Grad-CAM++ to enhance technical accuracy and build trust among decision-makers, supporting both immediate response and long-term recovery. If image quality and interpretability are neglected, the risk of biased assessments increases, particularly in low-income regions where infrastructure is harder to detect.

\subsubsection{Forest Fire Patterns and Lightning-Caused Detection in China}
An effective, context-aware approach uses regional pattern analysis to train models with ecological and geographic awareness, improving accuracy and cultural relevance. An ineffective, generic model that ignores local data may misrepresent fire regimes, leading to interventions that are misaligned with actual community needs and worsening outcomes.

\subsection{SYNTHESIS}

Together, these studies reveal that effective disaster response systems must go beyond technical precision. They must be:

\begin{itemize}
    \item \textbf{Timely} enabling early detection and rapid mobilization.
    \item \textbf{Accurate} leveraging augmentation, super-resolution, and hybrid architectures.
    \item \textbf{Trustworthy} incorporating explainability and stakeholder confidence.
    \item \textbf{Context-aware} integrating socioeconomic and regional data.
    \item \textbf{Equity-driven} ensuring vulnerable populations are not excluded due to data gaps.
\end{itemize}

AI systems that align with these principles can mitigate not amplify existing inequalities. Conversely, systems that ignore socioeconomic context risk turning technological interventions into liabilities, reinforcing disparities in aid, recovery, and resilience.


\section{Application of remote sensing in disaster response}

% This is the results section where we can describe the different application and some basic stats to show how well it can or cannot work (like in chinese mountain range paper)
% How we can use it to detect and classify damaged buildings (~3 paper examples)
% How we can use it for fire detection (2 paper examples)
% How we can use it for more general disaster detection (1 paper example)

Artificial intelligence techniques excel at finding complex non linear patterns in complex data which is otherwise differentiable from noise to humans or other pattern recognition tooling. It is not a huge surprise that AI then is capable of excelling at finding complex patterns in a huge variety of data leading to significant improvements over the previous state of art in a variety of areas (such as fast detection of wildfires, flash flooding, and risky icebergs in shipping routes). This has proven to be highly useful in the area of disaster detection due to being able to get meaningful results from combined many different sources of sensor data rather than any single detection source which may fail under particular circumstances (such as cloud cover preventing detection of wildfires).


\subsection{WILDFIRES}

Wildfire detection is an example of disaster detection where AI has been used since the 1990s. The authors of the paper begin with a review of ways various types of remote sensing data have led to improvements in rapid response systems. Over time, researchers have explored increasingly more complex data signal sources- from one dimensional inputs such as thermometers, to using increasingly higher resolution satellite cloud data, to complex sensing tools which have high dimensional outputs (which can be helpful where, for example, clouds might block the forests from view of the satellite imagery). This issue of cloud cover blocking data is a big problem, with systems entirely reliant on computer vision techniques only correctly detecting fires on historical satellite data in 30\% of cases.

In general, the quality of output system is dependent both on having high quality data, and designing systems to fully take advantage of the data that you do have. With this in mind, the paper sets out the goal of combining the strengths of computer vision techniques and transformer inspired mechanisms for more comprehensive analysis of wildfire patterns in a ConvNeXt-based architecture. This is able to combine many different sources of sensor data and extract meaningful patterns. The model is carefully designed to trade of computational complexity and accuracy, and many different model variations were released for different hardware types and use cases (ranging from super computer to in field local models).

\begin{quote}
\textit{"ConvNeXt was selected over traditional CNNs such as ResNet and pure transformer-based models like Vision Transformers (ViT) due to its balanced advantages. It achieves superior performance on vision tasks compared to ResNet, while offering efficient training. Unlike ViTs, which generally require very large datasets to perform well, ConvNeXt demands less data, making it better suited for moderately sized datasets."}
\end{quote}
\cite{elbohy2025fusion}


\subsection{FLOODING}

Flooding is the most frequent natural disaster causing widespread loss of life and destruction of property. Some flooding will develop slowly, but the most dangerous kind (flash floods) can develop very quickly, leaving minimal time to evacuate or otherwise prepare. This is an area then where small improvements can translate to significant reduction of casualties. Certain geographic areas which experience wet seasons are particularly susceptible to this danger- the paper focuses primarily on Malaysia, (which accounts for 60\% of it's total occurrences of natural disasters), but mentions that globally 1.81 billion people are exposed to flood risk. Beyond the human impact, flooding can have a significant effect on the economy of countries.

\begin{quote}
    " In 2021 alone, water-related disaster resulted in economic losses amounting to \$224.2 billion  globally, nearly doubling the annual average of \$117.8 billion recorded from 2001 to 2020. A recent report also predicts that floods alone are expected to erode more than \$2 trillion from the global GDP by 2050."
\end{quote}

\subsubsection{Detection of flash floods}

Like wildfire detection, statistical analysis and machine learning has been applied to try to improve detection of floods for some time. Traditional methods have focused on hydrological data and satellite observations but have had limitation such as temporal and spatial resolution as well as accuracy performance. Satellite (like Landsat and MODIS) imagery is massively negatively hindered by cloud cover, a slightly ironic limitation given the source of flooding would generally imply high cloud coverage. Other methods such as radar have other benefits for detecting water bodies, mapping flood extents, and tracking changes in land cover.

\subsubsection{YOLO Approach}

The paper tries an approach of building a computer vision based classifier using a dataset of 3750 images collected from various generative AI tools, which were then preprocessed to get a final dataset of 6374 images of flood scenarios. The prompts used to specify the images included specifying the expected country (Malaysia) and specified the angles they knew they would need for the classifier. This is a uniquely low cost method of gathering a comprehensive dataset. In the context of Malaysia, rural areas are more highly effected by flash flooding, and in general flooding has a higher impact on areas with higher poverty. Such a low cost method of gathering data would be particularly valuable to higher poverty areas.

The final results are good, but not beating the state of the art with a mAP of 0.79 and F1-score of 90.8 (in comparison to Mask-R-CNN achieving mAP of 0.95 and F1-score of 97). The uniquely low cost way of building the dataset combined with fairly strong performance do indicate that this is a promising direction to explore, and the paper suggests future research directions which they believe would improve performance further. Particularly in areas of higher poverty, non synthetic datasets may not even exist, so understanding how to get good performance from synthetic data may help reduce inequities associated with this.


\subsection{OTHER APPLICATIONS}

\subsubsection{Water Detection}

Another aspect of flood detection is the post flooding stage. The YOLO based model is aims to improve detection of the flood itself, whereas the post flooding stage is based on fixing the problems caused by the flood. This paper builds a classifier using satellite imagery of buildings pre and post flood with simple labels to indicate different sorts of damage.  The paper suggests particular architectural designs leading to their success such as separate encoders developed for pre and post disaster imagery, and also pre training on non disaster satellite imagery. The model achieved strong performances of 91.4\% accuracy.  A model like this is helpful for governments to understand local damage estimates can be especially helpful in prioritizing relief efforts and climate resilient redevelopment.

\subsubsection{Iceberg Detection}

A more commercially focused project was to use artificial intelligence to detect icebergs in northern shipping routes.  Due to the enormous range of weather, lighting, sea,  and the physical conditions of the icebergs themselves, creating a robust classifier for this has proven to be an enormously complex task. The data required is also highly difficult to get and required extensive expert analysis by GIS specialists to be properly labeled. Conversely, such a system would be enormously valuable to the shipping industry, and therefore they are strongly motivated to invest in improving the technology. The final CNN based model is able to encode many features to build a robust classifier performing better than previous methods. This is an example of commercial value driving research directions, but this later leading to humanitarian benefits.


\section{Challenges of using remote sensing for disaster response}


\subsection{TECHNICAL \& DEPLOYMENT CHALLENGES}


\subsubsection{Resource-constrained deployment \& real-time processing}
Powerful machine learning models require significant computational resources for real-time processing during critical response phases. While these models often deliver higher performance than lightweight alternatives, deploying them on embedded devices, mobile systems, or Unmanned Aerial Vehicles (UAVs) is hindered by limited processing power, strict energy requirements, and constrained communication bandwidth \cite{elbohy2025fusion}. For instance, Padmawar et al.'s flood forecasting system using Convolutional Neural Networks (CNN) + Modified Particle Swarm Optimization demonstrate high performance, but are highly complex and expensive in real-time systems. Similarly, while Elbohy et al.'s ConvNeXt-Small model shows promise for wildfire detection, achieving 99.05\% test accuracy on the Wildfire Prediction Dataset, it still lacks practical deployment strategies for real-world alert systems \cite{elbohy2025fusion}. This results in a constant trade-off between achieving high model accuracy and ensuring feasible deployment in post-disaster events.

\subsubsection{Model interpretability \& trust issues}
Deep learning models are frequently criticized as ``black boxes,'' offering limited transparency into decision-making, which is problematic in post-disaster contexts where trust and accountability are essential. Explainable AI methods such as Grad-CAM++ can highlight image regions associated with post-disaster damage, but when models lack robust internal representations, the resulting visualizations often appear scattered or inconsistent and fail to capture the overall structural context. Future research should focus on explainability-driven training strategies such as using attention refinement or uncertainty-aware learning to improve how models allocate attention, so that Grad-CAM outputs highlight meaningful disaster-related features rather than scattered or irrelevant regions \cite{lagapEnhancingPostDisasterDamage2025}.

\subsubsection{Cross-event generalization \& class imbalance}
Kim et al. (2022) investigated the application of computer vision techniques for water-related disaster damage assessment using satellite imagery. They found that remote sensing models often struggle to generalise across disaster types and regions. Systems trained on specific events show significant performance degradation when applied to different disaster contexts, with accuracy falling from 85.9\% in-domain to 80.3\% out-of-domain events \cite{kimDisasterAssessmentUsing2022}. Cross-event testing further highlights this limitation, with F1 scores dropping below 0.5 for disasters such as flooding and tsunamis (Sunda Strait: 0.164, Midwestern Flooding: 0.495). These challenges are exacerbated by class imbalance such as those found in the Philippines post-Typhoon Haiyan dataset where critical recovery states such as ``New buildings'' (180 samples) are heavily underrepresented compared to ``Not damaged'' (625 samples), and by systematic data gaps in which submerged or debris-obscured structures are missing \cite{lagapEnhancingPostDisasterDamage2025}.


\subsection{DATA ACQUISITION \& QUALITY CHALLENGES}

\subsubsection{Cost, accessibility \& temporal constraints}
Access to very high-resolution satellite data is often limited, delayed, or cost-prohibitive due to cloud cover and operational constraints, as Lagap and Ghaffarian found when working with the Tacloban, Philippines post-Typhoon Haiyan dataset. Satellites face an inherent trade-off between spatial and temporal resolution. Higher spatial resolution satellites have longer revisit cycles that cannot meet the timeliness requirements for disaster response, while lower resolution satellites with more frequent coverage lack the spatial detail needed for damage assessment. To address this gap, Lagap and Ghaffarian proposed ESRGAN as a cost-effective solution that enhances readily available low-resolution imagery, improving classification accuracy by approximately 4-5\% for post-disaster damage detection without requiring expensive very high-resolution data sources \cite{lagapEnhancingPostDisasterDamage2025}.

\subsubsection{Atmospheric \& environmental limitations}
Disasters themselves often reduce the effectiveness of remote sensing. Cloud cover, smoke, and atmospheric disturbances can obscure satellite views during critical periods \cite{lagapEnhancingPostDisasterDamage2025}. In Heilongjiang Province between 2013 and 2020, the VIIRS satellite detected only 14.8\% of 298 forest fires caused by lightning strikes, with cloud cover and satellite transit timing preventing observation of the remaining 85.2\% \cite{jiaoForestFirePatterns2023}. Dense urban environments and debris further limit the effectiveness of optical imagery \cite{lagapEnhancingPostDisasterDamage2025}, while floods often coincide with heavy cloud cover that obstructs systems such as Landsat and MODIS \cite{teohExploringGenerativeAI2024}. These conditions underscore a critical challenge that disasters frequently occur under circumstances that compromise the very sensing capabilities needed for effective response.


\subsection{OPERATIONAL \& METHODOLOGICAL CHALLENGES}

\subsubsection{Multi-temporal analysis \& recovery discrimination}
Effective post-disaster assessment requires tracking structural changes across three key periods: pre-disaster, event, and post-disaster. Distinguishing between damage, recovery, and new construction over time demands more advanced feature extraction as current models still misclassify partially damaged, unrepaired, and recovered structures. This is evident in the Tacloban post-Typhoon Haiyan dataset where "Not Recovered" and "Recovered" categories remain particularly challenging to differentiate. The challenge is compounded by the need to separate damage-specific features from seasonal changes and urban development between image acquisitions \cite{kimDisasterAssessmentUsing2022}. While models such as Vision Transformers (ViT) can compare all three temporal frames given high-resolution imagery, this temporal reasoning remains inconsistent across damage categories \cite{lagapEnhancingPostDisasterDamage2025}.

\subsubsection{Synthetic data \& training limitations}
Synthetic imagery has been explored to address data scarcity, class imbalance, and scenario diversity in disaster response modeling. While effective for augmenting rare classes, achieving mAP50 scores of 96.7\% and F1 scores of 90.8\% in flood detection as demonstrated by Teoh et al. using YOLO-based models on Malaysian flood scenarios \cite{teohExploringGenerativeAI2024}, generated data often lacks realism and requires systematic filtering to remove artifacts such as cartoon-like imagery. Current approaches also face restrictions on the volume of data AI tools can generate and the need for carefully designed prompts to reduce bias. Lastly, synthetic datasets cannot capture the complex physical and spatial dynamics of real disasters, struggling to replicate environmental interactions and temporal dynamics across pre-disaster, event, and post-disaster stages.

\section{Conclusion}
Across five complementary studies, remote sensing emerges as central to disaster response: it delivers fast situation awareness from satellites and drones, but impact is limited by observability, domain shift, and label constraints.

Empirically, the papers demonstrate AI's value across various disaster scenarios. For wildfire detection, a hybrid ConvNeXt-Transformer model achieved 99.05\% test accuracy on satellite images \cite{elbohy2025fusion}. However, real-world performance is often limited by environmental factors; in Heilongjiang, cloud cover and satellite revisit timing meant that fewer than 15\% of lightning-caused fires were detected, despite lightning accounting for most fires in the region \cite{jiaoForestFirePatterns2023}. For assessing building damage, a model using pre- and post-disaster imagery reached 91.4\% accuracy within its training domain but showed a drop in performance on out-of-domain events \cite{kimDisasterAssessmentUsing2022}. To address data scarcity in flood detection, a YOLOv8 model trained on synthetic images produced promising results, though tests on real-world drone footage highlighted challenges in transferring from synthetic to real data \cite{teohExploringGenerativeAI2024}. Finally, to improve detection of small or underrepresented features, an Enhanced Super-Resolution GAN (ESRGAN) successfully increased classification accuracy by 4-5\% by enhancing low-resolution imagery, improving recall for critical minority classes \cite{lagapEnhancingPostDisasterDamage2025}.

\subsection{IMPLICATIONS FOR PRACTICE AND EQUITY}
The studies collectively show that \emph{effective} AI-enabled sensing accelerates triage and targeting (e.g., earlier wildfire alerts, faster flood asset detection, more complete disaster surveys), which shortens time-to-aid and reduces waste. Conversely, \emph{ineffective} deployment can misallocate resources and systematically underserve vulnerable communities. Thus, operational systems must be \textbf{timely}, \textbf{accurate}, \textbf{trustworthy/transparent}, \textbf{context-aware}, and \textbf{equity-driven}. Current efforts include combining super-resolution and augmentation to raise recall on small/rare classes; using explainability (Grad-CAM++/uncertainty) to build stakeholder confidence; and grounding models in local ecological and socioeconomic patterns so decisions remain culturally and regionally appropriate.

\subsection{CURRENT CHALLENGES}
\textit{Technical \& deployment:} (i) resource-constrained, on-edge inference for UAVs/field kits; (ii) interpretability and calibrated uncertainty for accountable decisions; (iii) robust operation under bandwidth/power limits and adverse comms.\\
\textit{Data acquisition \& quality:} (i) cost/access and latency of high-resolution imagery; (ii) atmospheric/occlusion limits (cloud, smoke) that suppress detection rates (e.g., low VIIRS visibility for lightning fires); (iii) label scarcity/imbalance, especially for minority yet critical classes.\\
\textit{Operational \& methodological:} (i) cross-event/region generalization gaps (OOD drops despite strong lab metrics); (ii) multi-temporal reasoning to separate damage vs.\ recovery/new build; (iii) benefits and pitfalls of synthetic data (high mAP in lab, brittleness in field without standardized capture and curation).

\subsection{FUTURE DIRECTIONS}
\begin{enumerate}
  \item \textit{Task-to-action frameworks:} operationalize concepts like FloodIntel (tasking$\rightarrow$standardized capture$\rightarrow$multi-modal fusion$\rightarrow$prioritized dispatch) with auditable decisions and latency budgets.
  \item \textit{Smaller, faster models at the edge:} distill/quantize strong backbones (ConvNeXt-S, YOLOv8n/s/m) for drones, field laptops, and small satellites, with calibrated uncertainty and fail-safes.
  \item \textit{Richer fusion:} couple SAR+optical+thermal+UAV with environmental context to operate through clouds/smoke and separate look-alikes (e.g recovered building and new build)
  \item \textit{Label-efficient learning:} self-supervision, weak/active learning, and ESRGAN super-resolution to raise recall on minority classes with limited ground truth.
  \item \textit{Data \& protocol standardization:} define drone flight profiles, view angles, GSD, and annotation rubrics so synthetic and real images match at train and test time.
  \item \textit{Fair, reliable evaluation:} report imbalance-aware metrics, OOD tests, occlusion stress tests, uncertainty calibration, and end-to-end latency, not only headline mAP or accuracy.
\end{enumerate}


In sum, remote sensing already yields earlier wildfire alerts, faster flood triage, and more complete disaster surveys. Realizing its full promise now hinges on (i) standardizing data collection to reduce domain gaps, (ii) hardening models against shift with uncertainty-aware, multi-modal fusion, (iii) boosting rare-class recall (via ESRGANs and active/weak supervision), and (iv) embedding compact, trustworthy predictors inside equitable, auditable workflows so that AI \emph{mitigates}, rather than amplifies, existing disparities in aid, recovery, and resilience.


\bibliographystyle{IEEEtran}
\bibliography{references}
  
\end{document}
