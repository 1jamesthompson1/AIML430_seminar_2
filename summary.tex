\documentclass[conference,a4paper]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
%Template version as of 6/27/2024

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}

\usepackage{textcomp}
\usepackage{tikz}
\usepackage{booktabs}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{bookmark}
\usepackage{array}
\usepackage{tabularx}
\usepackage{amssymb} 


\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

% Custom figure command: pass filename and caption
\newcommand{\cfigure}[2]{%
  \begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{figures/#1.png}%
    \caption{#2}%
    \label{fig:#1}%
  \end{figure}%

}
\title{AI for disaster detection and response using satellite imagery}

\author{Dwayne Mark Acosta (300665276) \\ Mohamed Amine Benaziza (300684553) \\ David Franz (300360491) \\ Ray Marange (300671115) \\ James Thompson (300680096)\\
\textit{Victoria University of Wellington}\\}
\date{\today}

\maketitle

\section{Introduction}

% Introduce this paper, It is a summary of ai disaster detection and problems using 5 primary papers (but hopefully more) ...
%% introduce the what remote sensing is
%% tell some statistics about how disaster are bad and increasing (the papers have lots of references)
%% more or less show that there is a great opportunity and need for better disaster response

\cite{elbohy2025fusion} etc...


\section{IMPLICATION OF EFFECTIVE OR INEFFECTIVE DISASTER RESPONSE}
Artificial intelligence has the potential to transform disaster response by accelerating decision-making, improving situational awareness, and optimizing resource allocation. However, the effectiveness of these systems is not solely technical it is deeply intertwined with social equity, data accessibility, and contextual relevance. The selected papers illustrate both the promise and the risks of AI-driven disaster management, especially when deployed in communities with limited infrastructure or socioeconomic vulnerability.
\subsection{DISASTER ASSESSMENT USING COMPUTER VISION AND SATELLITE IMAGERY}
\subsubsection{Effective response}
Rapid quantification of structural damage enables targeted aid delivery to the most affected zones, reducing recovery time and minimizing resource waste.
\subsubsection{Ineffective response}
Misclassification or omission of damage—especially in informal settlements or low-visibility regions—can result in inequitable aid distribution, leaving vulnerable populations underserved.
\subsection{EXPLORING GENERATIVE AI FOR YOLO-BASED OBJECT DETECTION}
\subsubsection{Effective response}
Generative augmentation addresses data scarcity, allowing object detection models to generalize across novel disaster zones and support real-time situational awareness.
\subsubsection{Ineffective response}
Over-reliance on synthetic data without validation may produce brittle models that fail in diverse real-world contexts, particularly in regions lacking annotated datasets.
\subsection{FUSION OF CNN AND TRANSFORMER ARCHITECTURES FOR PROACTIVE WILDFIRE DETECTION}
\subsubsection{Effective response}
Hybrid ConvNeXt-Transformer models enable early wildfire detection, facilitating timely evacuations and reducing environmental and human impact.
\subsubsection{Ineffective response}
Delayed alerts due to poor integration or regional blind spots can allow fires to escalate before responders mobilize, especially in remote or underserved areas.
\subsection{ENHANCING POST-DISASTER DAMAGE DETECTION WITH ESRGAN}
\subsubsection{Effective response}
Super-resolution and explainability tools (e.g., Grad-CAM++) enhance technical accuracy and build trust among decision-makers, supporting both immediate response and long-term recovery.
\subsubsection{Ineffective response}
Neglecting image quality and interpretability risks biased assessments, particularly in low-income regions where infrastructure may be harder to detect or classify.
\subsection{FOREST FIRE PATTERNS AND LIGHTNING-CAUSED DETECTION IN CHINA}
\subsubsection{Effective response}
Regional pattern analysis ensures models are trained with ecological and geographic awareness, improving accuracy and cultural relevance in intervention strategies.
\subsubsection{Ineffective response}
Generic models that ignore local data may misrepresent fire regimes, leading to interventions that are misaligned with actual community needs.
\subsection{SYNTHESIS}
Together, these studies reveal that effective disaster response systems must go beyond technical precision. They must be:
\begin{itemize}
    \item \textbf{Timely} — enabling early detection and rapid mobilization.
    \item \textbf{Accurate} — leveraging augmentation, super-resolution, and hybrid architectures.
    \item \textbf{Trustworthy} — incorporating explainability and stakeholder confidence.
    \item \textbf{Context-aware} — integrating socioeconomic and regional data.
    \item \textbf{Equity-driven} — ensuring vulnerable populations are not excluded due to data gaps.
\end{itemize}
AI systems that align with these principles can mitigate not amplify existing inequalities. Conversely, systems that ignore socioeconomic context risk turning technological interventions into liabilities, reinforcing disparities in aid, recovery, and resilience.


\section{Application of remote sensing in disaster response}

% This is the results section where we can describe the different application and some basic stats to show how well it can or cannot work (like in chinese mountain range paper)
% How we can use it to detect and classify damaged buildings (~3 paper examples)
% How we can use it for fire detection (2 paper examples)
% How we can use it for more general disaster detection (1 paper example)

\section{Challenges of using remote sensing for disaster response}


\subsection{TECHNICAL \& DEPLOYMENT CHALLENGES}

\subsubsection{\textbf{Resource-constrained deployment \& real-time processing}}
A major challenge for remote sensing in disaster response is the difficulty of meeting the computational demands of modern machine learning and deep learning models required for real-time processing during critical response phases. While these models often deliver higher performance than lightweight alternatives, deploying them on embedded devices, mobile systems, or Unmanned Aerial Vehicles (UAVs) is hindered by limited processing power, strict energy requirements, and constrained communication bandwidth \cite{elbohy2025fusion}. For instance, flood forecasting systems using Convolutional Neural Networks (CNN) + Modified Particle Swarm Optimization demonstrate high performance but are highly complex and expensive in real-time systems. While CNN-based models like ConvNeXt-Small show promise for wildfire detection, achieving 99.05\% test accuracy, they still lack practical deployment strategies for real-world alert systems \cite{elbohy2025fusion}. This results in a constant trade-off between achieving high model accuracy and ensuring feasible deployment in post-disaster events.

\subsubsection{\textbf{Model interpretability \& trust issues}}
Deep learning models are frequently criticized as ``black boxes,'' offering limited transparency into decision-making, which is problematic in post-disaster contexts where trust and accountability are essential. Explainable AI methods such as Grad-CAM++ can highlight image regions associated with post-disaster damage, but when models lack robust internal representations, the resulting visualizations often appear scattered or inconsistent and fail to capture the overall structural context. Future research should focus on explainability-driven training strategies such as using attention refinement or uncertainty-aware learning to improve how models allocate attention, so that Grad-CAM outputs highlight meaningful disaster-related features rather than scattered or irrelevant regions \cite{lagapEnhancingPostDisasterDamage2025}.

\subsubsection{\textbf{Cross-event generalization \& class imbalance}}
Remote sensing models often struggle to generalise across disaster types and regions. Systems trained on specific events show significant performance degradation when applied to different disaster contexts, with accuracy falling from 85.9\% in-domain to 80.3\% out-of-domain events \cite{kimDisasterAssessmentUsing2022}. Cross-event testing further highlights this limitation, with F1 scores dropping below 0.5 for disasters such as flooding and tsunamis, where submerged buildings cause severe misclassification errors. These challenges are exacerbated by class imbalance, where critical recovery states such as ``New buildings'' (180 samples) are heavily underrepresented compared to ``Not damaged'' (625 samples), and by systematic data gaps in which submerged or debris-obscured structures are missing from training datasets \cite{lagapEnhancingPostDisasterDamage2025}.


\subsection{DATA ACQUISITION \& QUALITY CHALLENGES}

\subsubsection{\textbf{Cost, accessibility \& temporal constraints}}
Access to high-resolution satellite data is often expensive, difficult to acquire in real-time, or subject to cloud cover and operational delays \cite{lagapEnhancingPostDisasterDamage2025}. Due to the fixed temporal resolution of satellites, obtaining images immediately before and after disasters presents significant challenges, while higher-resolution satellites such as Landsat and Sentinel have longer revisit cycles that do not meet timeliness requirements for disaster response. The concentration of high-quality ground-truth data in developed countries also disadvantages disaster-prone developing countries that lack the statistical capacity and resources to produce quality local damage data for training effective models \cite{kimDisasterAssessmentUsing2022}.

\subsubsection{\textbf{Atmospheric \& environmental limitations}}
Disasters themselves often reduce the effectiveness of remote sensing. Cloud cover, smoke, and atmospheric disturbances can obscure satellite views during critical periods \cite{lagapEnhancingPostDisasterDamage2025}. In Heilongjiang Province between 2013 and 2020, the VIIRS satellite detected only 14.8\% of 298 forest fires caused by lightning strikes, with cloud cover and satellite transit timing preventing observation of the remaining 85.2\% \cite{jiaoForestFirePatterns2023}. Dense urban environments and debris further limit the effectiveness of optical imagery \cite{lagapEnhancingPostDisasterDamage2025}, while floods often coincide with heavy cloud cover that obstructs systems such as Landsat and MODIS \cite{teohExploringGenerativeAI2024}. These conditions underscore a critical challenge that disasters frequently occur under circumstances that compromise the very sensing capabilities needed for effective response.


\subsection{OPERATIONAL \& METHODOLOGICAL CHALLENGES}

\subsubsection{\textbf{Multi-temporal analysis \& recovery discrimination}}
Effective post-disaster assessment requires tracking structural changes across three key periods: pre-disaster, event, and post-disaster. Distinguishing between damage, recovery, and new construction over time demands more advanced feature extraction, but current models still misclassify partially damaged, unrepaired, and recovered structures. Most research still focuses on single-timeframe classification, limiting longitudinal recovery analysis. The challenge is compounded by the need to separate damage-specific features from seasonal changes and urban development between image acquisitions \cite{kimDisasterAssessmentUsing2022}. While models such as Vision Transformers (ViT) can compare all three temporal frames given high-resolution imagery, this temporal reasoning remains inconsistent across damage categories \cite{lagapEnhancingPostDisasterDamage2025}.

\subsubsection{\textbf{Synthetic data \& training limitations}}
Synthetic imagery has been explored to address data scarcity, class imbalance, and scenario diversity in disaster response modeling. While effective for augmenting rare classes, achieving mAP50 scores of 96.7\% and F1 scores of 90.8\% in flood detection \cite{teohExploringGenerativeAI2024}, generated data often lacks realism and requires systematic filtering to remove artifacts such as cartoon-like imagery. Current approaches also face restrictions on the volume of data AI tools can generate and the need for carefully designed prompts to reduce bias. Lastly, synthetic datasets cannot capture the complex physical and spatial dynamics of real disasters, struggling to replicate environmental interactions and temporal dynamics across pre-disaster, event, and post-disaster stages.


\section{Conclusion}

Across six complementary studies, remote sensing emerges as central to disaster response: it delivers fast situation awareness from satellites and drones, but impact is limited by observability, domain shift, and label constraints.

Empirically, the papers span fires, floods, sea-ice hazards, and built-environment damage. In Heilongjiang, satellites track seasonal fire trends but miss many lightning ignitions because of clouds and revisit timing: lightning causes 77.6\% of fires, yet under 30\% of all fires are detected by VIIRS (Visible Infrared Imaging Radiometer Suite) and under 15\% of lightning fires, and the monitorable fraction falls as lightning’s share rises ($r=-0.888$, $p=0.003$). When satellites do see events they typically \emph{precede} ground reports by about 1--8 hours, showing real early-warning value. For building damage, a lightweight pseudo-siamese grid classifier reaches about 91\% accuracy in-domain and about 80\% out-of-domain, and remains usable on new crises (Providencia: 97.5\% accuracy, $F_1=0.851$) despite coarse labels. For flood response, YOLOv8 trained on generative synthetic imagery attains $\text{mAP}_{50}=0.967$, $\text{mAP}_{[0.5,0.95]}=0.787$, and $F_1=0.908$, while tests on real drone scenes reveal transfer brittleness that argues for standardized capture and curation. For wildfires, a ConvNeXt-Small hybrid (CNN+Transformer) delivers about 99.05\% test accuracy on satellite tiles. In polar waters, fusing RCM SAR with ViT features, simple statistics, and ERA5 winds enables four-way classification (open water, sea ice, and each “with iceberg”) at 96.5\% accuracy with roughly 1\% false alarms; collapsing to target vs.\ no-target yields 98.9\%. Finally, enhanced super-resolution GANs (ESRGAN) directly target small objects and minority classes, improving recall where post-disaster monitoring needs it most.

\textbf{Current challenges.} Common issues recur across hazards and sensors:
\begin{itemize}
  \item \textit{Observability gaps:} cloud or smoke occlusion, night/illumination limits for optical, and revisit latency (e.g., May--July lightning fires in the Daxing’an Mountains).
  \item \textit{Domain shift:} synthetic$\rightarrow$real, drone$\rightarrow$satellite, region$\rightarrow$region can erode field performance despite strong lab metrics.
  \item \textit{Label scarcity and imbalance:} rare but critical classes (destroyed buildings, small icebergs, early fire pixels) and coarse/incomplete labels bias training and evaluation.
  \item \textit{Sensor heterogeneity:} mixing optical, SAR, thermal, UAV, and reanalyses requires careful calibration, metadata discipline, and uncertainty handling.
  \item \textit{Deployment constraints:} bandwidth, power, and the need for robust, on-edge inference under adverse weather and communications.
\end{itemize}

\textbf{Future directions.} The line of work across these papers points to end-to-end, field-robust pipelines:
\begin{enumerate}
  \item \textit{Task-to-action frameworks:} operationalize concepts like FloodIntel (tasking$\rightarrow$standardized capture$\rightarrow$multi-modal fusion$\rightarrow$prioritized dispatch) with auditable decisions and latency budgets.
  \item \textit{Smaller, faster models at the edge:} distill/quantize strong backbones (ConvNeXt-S, YOLOv8n/s/m) for drones, field laptops, and small satellites, with calibrated uncertainty.
  \item \textit{Richer fusion:} couple SAR+optical+thermal+UAV with environmental context (e.g., ERA5 winds) to separate look-alikes (open water vs.\ sea ice) and operate through clouds/smoke.
  \item \textit{Label-efficient learning:} self-supervision, weak/active learning, and ESRGAN super-resolution to raise recall on minority classes with limited ground truth.
  \item \textit{Data and protocol standardization:} define drone flight profiles, view angles, ground sampling distance, and annotation rubrics so synthetic and real images match at train and test time.
  \item \textit{Fair, reliable evaluation:} report imbalance-aware metrics, out-of-domain tests, occlusion stress tests, and end-to-end latency, not only headline mAP or accuracy.
\end{enumerate}

In sum, remote sensing already yields earlier wildfire alerts, faster flood triage, and safer polar navigation. Realizing its full promise now hinges on standardizing data collection, hardening models against shift, boosting rare-class recall (via ESRGANs and active learning), and embedding compact, trustworthy predictors inside operational workflows for end-to-end disaster response.


\bibliographystyle{IEEEtran}
\bibliography{references}
  
\end{document}
