\documentclass[conference,a4paper]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
%Template version as of 6/27/2024

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}

\usepackage{textcomp}
\usepackage{tikz}
\usepackage{booktabs}
\usepackage{xcolor}
\usepackage{hyperref}
\usepackage{array}
\usepackage{tabularx}
\usepackage{amssymb} 


\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

% Custom figure command: pass filename and caption
\newcommand{\cfigure}[2]{%
  \begin{figure}[h]
    \centering
    \includegraphics[width=\linewidth]{figures/#1.png}%
    \caption{#2}%
    \label{fig:#1}%
  \end{figure}%

}
\title{AI for disaster detection and response using satellite imagery}

\author{Dwayne Mark Acosta (300665276) \\ Mohamed Amine Benaziza (300684553) \\ David Franz (300360491) \\ Ray Marange (300671115) \\ James Thompson (300680096)\\
\textit{Victoria University of Wellington}\\}
\date{\today}

\maketitle

\section{Introduction}

% Introduce this paper, It is a summary of ai disaster detection and problems using 5 primary papers (but hopefully more) ...
%% introduce the what remote sensing is
%% tell some statistics about how disaster are bad and increasing (the papers have lots of references)
%% more or less show that there is a great opportunity and need for better disaster response

\cite{elbohy2025fusion} etc...


\section{Implication of effective or ineffective disaster response}

% Disaster disproportionately effect the poor and economically vulnerable
% Can amplify existing inequalities in communities that don't have survellance or data collection. Or help mitagte it due to easier data collection
% Talking about how it could include socioeconomic data into the disaster response information (paper example)
% (paper example) from all of the introductions and discussion sections.

\section{Application of remote sensing in disaster response}

% This is the results section where we can describe the different application and some basic stats to show how well it can or cannot work (like in chinese mountain range paper)
% How we can use it to detect and classify damaged buildings (~3 paper examples)
% How we can use it for fire detection (2 paper examples)
% How we can use it for more general disaster detection (1 paper example)

\section{Challenges of using remote sensing for disaster response}

\subsection{Data availability}

% Using super sampling to make low res data more useful (paper example)
% Using genAI to make up synthetic data (paper example)

\subsubsection{Compute constraints}

% How it can be hard to run large models on limited hardware and bandwidth
% Embedded processing due to bandwidth contraints from satellites (paper example)
% Compute constraints on the ground and speed requirements (paper example)

\section{Conclusion}
Across six complementary studies, remote sensing emerges as central to disaster response: it delivers fast situation awareness from satellites and drones, but impact is limited by observability, domain shift, and label constraints.

Empirically, the papers span fires, floods, sea-ice hazards, and built-environment damage. In Heilongjiang, satellites track seasonal fire trends but miss many lightning ignitions because of clouds and revisit timing: lightning causes 77.6\% of fires, yet under 30\% of all fires are detected by VIIRS and under 15\% of lightning fires, and the monitorable fraction falls as lightning’s share rises ($r=-0.888$, $p=0.003$). When satellites do see events they typically \emph{precede} ground reports by about 1--8 hours, showing real early-warning value. For building damage, a lightweight pseudo-siamese grid classifier reaches about 91\% accuracy in-domain and about 80\% out-of-domain, and remains usable on new crises (Providencia: 97.5\% accuracy, $F_1=0.851$) despite coarse labels. For flood response, YOLOv8 trained on generative synthetic imagery attains $\text{mAP}_{50}=0.967$, $\text{mAP}_{[0.5,0.95]}=0.787$, and $F_1=0.908$, while tests on real drone scenes reveal transfer brittleness that argues for standardized capture and curation. For wildfires, a ConvNeXt-Small hybrid (CNN+Transformer) delivers about 99.05\% test accuracy on satellite tiles. In polar waters, fusing RCM SAR with ViT features, simple statistics, and ERA5 winds enables four-way classification (open water, sea ice, and each “with iceberg”) at 96.5\% accuracy with roughly 1\% false alarms; collapsing to target vs.\ no-target yields 98.9\%. Finally, enhanced super-resolution GANs (ESRGAN) directly target small objects and minority classes, improving recall where post-disaster monitoring needs it most.

\paragraph{Implications for practice and equity.}
The studies collectively show that \emph{effective} AI-enabled sensing accelerates triage and targeting (e.g., earlier wildfire alerts, faster flood asset detection, more reliable polar navigation), which shortens time-to-aid and reduces waste. Conversely, \emph{ineffective} deployment---from brittle synthetic-to-real transfer to blind spots over informal settlements or cloud-obscured regions---can misallocate resources and systematically underserve vulnerable communities. Thus, operational systems must be \textbf{timely}, \textbf{accurate}, \textbf{trustworthy/transparent}, \textbf{context-aware}, and \textbf{equity-driven}: e.g., combining super-resolution and augmentation to raise recall on small/rare classes; using explainability (Grad-CAM++/uncertainty) to build stakeholder confidence; and grounding models in local ecological and socioeconomic patterns so decisions remain culturally and regionally appropriate.

\paragraph{Current challenges .}
\textit{Technical \& deployment:} (i) resource-constrained, on-edge inference for UAVs/field kits; (ii) interpretability and calibrated uncertainty for accountable decisions; (iii) robust operation under bandwidth/power limits and adverse comms.\\
\textit{Data acquisition \& quality:} (i) cost/access and latency of high-resolution imagery; (ii) atmospheric/occlusion limits (cloud, smoke) that suppress detection rates (e.g., low VIIRS visibility for lightning fires); (iii) label scarcity/imbalance, especially for minority yet critical classes.\\
\textit{Operational \& methodological:} (i) cross-event/region generalization gaps (OOD drops despite strong lab metrics); (ii) multi-temporal reasoning to separate damage vs.\ recovery/new build; (iii) benefits and pitfalls of synthetic data (high mAP in lab, brittleness in field without standardized capture and curation).

\paragraph{Future directions .}
\begin{enumerate}
  \item \textit{Task-to-action frameworks :} operationalize concepts like FloodIntel (tasking$\rightarrow$standardized capture$\rightarrow$multi-modal fusion$\rightarrow$prioritized dispatch) with auditable decisions and latency budgets.
  \item \textit{Smaller, faster models at the edge :} distill/quantize strong backbones (ConvNeXt-S, YOLOv8n/s/m) for drones, field laptops, and small satellites, with calibrated uncertainty and fail-safes.
  \item \textit{Richer fusion :} couple SAR+optical+thermal+UAV with environmental context (e.g., ERA5 winds) to operate through clouds/smoke and separate look-alikes (e.g., open water vs.\ sea ice).
  \item \textit{Label-efficient learning :} self-supervision, weak/active learning, and ESRGAN super-resolution to raise recall on minority classes with limited ground truth.
  \item \textit{Data \& protocol standardization :} define drone flight profiles, view angles, GSD, and annotation rubrics so synthetic and real images match at train and test time.
  \item \textit{Fair, reliable evaluation :} report imbalance-aware metrics, OOD tests, occlusion stress tests, uncertainty calibration, and end-to-end latency, not only headline mAP or accuracy.
\end{enumerate}

In sum, remote sensing already yields earlier wildfire alerts, faster flood triage, and safer polar navigation. Realizing its full promise now hinges on (i) standardizing data collection to reduce domain gaps, (ii) hardening models against shift with uncertainty-aware, multi-modal fusion, (iii) boosting rare-class recall (via ESRGANs and active/weak supervision), and (iv) embedding compact, trustworthy predictors inside equitable, auditable workflows---so that AI \emph{mitigates}, rather than amplifies, existing disparities in aid, recovery, and resilience.


\bibliographystyle{IEEEtran}
\bibliography{references}
  
\end{document}
