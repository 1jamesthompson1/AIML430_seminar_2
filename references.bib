@article{elbohy2025fusion,
  title = {Fusion of {{CNN}} and Transformer Architectures for Proactive Wildfire Detection in Satellite Imagery.},
  author = {Elbohy, Shereen Essam and Nasr, Mona M and Mousa, Farid Ali},
  year = {2025},
  journal = {International Journal of Advanced Computer Science \& Applications},
  volume = {16},
  number = {6},
  file = {/home/james/snap/zotero-snap/common/Zotero/storage/Y5TTAAUC/Elbohy et al. - 2025 - Fusion of CNN and transformer architectures for proactive wildfire detection in satellite imagery..pdf}
}

@article{jiaoForestFirePatterns2023,
  title = {Forest {{Fire Patterns}} and {{Lightning-Caused Forest Fire Detection}} in {{Heilongjiang Province}} of {{China Using Satellite Data}}},
  author = {Jiao, Qiangying and Fan, Meng and Tao, Jinhua and Wang, Weiye and Liu, Di and Wang, Ping},
  year = {2023},
  month = apr,
  journal = {Fire},
  volume = {6},
  number = {4},
  pages = {166},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2571-6255},
  doi = {10.3390/fire6040166},
  urldate = {2025-09-04},
  abstract = {Large forest fires can cause significant damage to forest ecosystems and threaten human life and property. Heilongjiang Province is a major forested area in China with the highest number and concentration of lightning-caused forest fires in the country. This study examined the spatial and temporal distribution patterns of forest fires in Heilongjiang Province, as well as the ability of satellite remote sensing to detect these fires using VIIRS 375 m fire point data, ground history forest fire point data, and land cover dataset. The study also investigated the occurrence patterns of lightning-caused forest fires and the factors affecting satellite identification of these fires through case studies. Results show that April has the highest annual number of forest fires, with 77.6\% of forest fires being caused by lightning. However, less than 30\% of forest fires can be effectively detected by satellites, and lightning-caused forest fires account for less than 15\% of all fires. There is a significant negative correlation between the two. Lightning-caused forest fires are concentrated in the Daxing'an Mountains between May and July, and are difficult to monitor by satellites due to cloud cover and lack of satellite transit. Overall, the trend observed in the number of forest fire pixels that are monitored by satellite remote sensing systems is generally indicative of the trends in the actual number of forest fires. However, lightning-caused forest fires are the primary cause of forest fires in Heilongjiang Province, and satellite remote sensing is relatively weak in monitoring these fires due to weather conditions and the timing of satellite transit.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {historically recorded forest fires,lightning-caused forest fires,patterns of forest fire distribution,satellite remote sensing},
  file = {/home/james/snap/zotero-snap/common/Zotero/storage/A46B65E9/Jiao et al. - 2023 - Forest Fire Patterns and Lightning-Caused Forest Fire Detection in Heilongjiang Province of China Us.pdf}
}

@article{kimDisasterAssessmentUsing2022,
  title = {Disaster Assessment Using Computer Vision and Satellite Imagery: {{Applications}} in Detecting Water-Related Building Damages},
  shorttitle = {Disaster Assessment Using Computer Vision and Satellite Imagery},
  author = {Kim, Danu and Won, Jeongkyung and Lee, Eunji and Park, Kyung Ryul and Kim, Jihee and Park, Sangyoon and Yang, Hyunjoo and Cha, Meeyoung},
  year = {2022},
  month = oct,
  journal = {Frontiers in Environmental Science},
  volume = {10},
  publisher = {Frontiers},
  issn = {2296-665X},
  doi = {10.3389/fenvs.2022.969758},
  urldate = {2025-09-04},
  abstract = {The increasing frequency and severity of water-related disasters such as floods, tornadoes, hurricanes, and tsunamis in low- and middle-income countries exemplify the uneven effects of global climate change. The vulnerability of high-risk societies to natural disasters has continued to increase. To develop an effective and efficient adaptation strategy, local damage assessments must be timely, exhaustive, and accurate. We propose a novel deep-learning-based solution that uses pairs of pre- and post-disaster satellite images to identify water-related disaster-affected regions. The model extracts features of pre- and post-disaster images and uses the feature difference with them to predict damage in the pair. We demonstrate that the model can successfully identify local destruction using less granular and less complex ground-truth data than those used by previous segmentation models. When tested with various water-related disasters, our detection model reported an accuracy of 91.4\% in spotting areas with damaged buildings. It also achieved a reliable performance of 80.3\% in out-of-domain settings. Our deep learning-based damage assessment model can help direct resources to areas most vulnerable to climate disasters, reducing their impacts while promoting adaptive capacities for climate-resilient development in the most vulnerable regions.},
  langid = {english},
  keywords = {Computer Vision,damage detection,Daytime satellite imagery,Disaster response,machine learning,Natural disaster},
  file = {/home/james/snap/zotero-snap/common/Zotero/storage/PYGKKZZP/Kim et al. - 2022 - Disaster assessment using computer vision and satellite imagery Applications in detecting water-rel.pdf}
}

@article{lagapEnhancingPostDisasterDamage2025,
  title = {Enhancing {{Post-Disaster Damage Detection}} and {{Recovery Monitoring}} by {{Addressing Class Imbalance}} in {{Satellite Imagery Using Enhanced Super-Resolution GANs}} ({{ESRGAN}})},
  author = {Lagap, Umut and Ghaffarian, Saman},
  year = {2025},
  month = jul,
  journal = {The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences},
  volume = {XLVIII-G-2025},
  pages = {853--860},
  publisher = {Copernicus GmbH},
  issn = {1682-1750},
  doi = {10.5194/isprs-archives-XLVIII-G-2025-853-2025},
  urldate = {2025-09-04},
  abstract = {Access to very high-resolution (HR) satellite imagery is often limited, delayed, or cost-prohibitive, restricting accurate and timely post-disaster damage detection and recovery monitoring (PDDRM). Additionally, class imbalance in disaster classification datasets further complicates deep learning (DL)-based assessments. This study addresses these challenges by leveraging ESRGAN to enhance low-resolution (LR) satellite imagery, thereby improving damage classification accuracy and the ability to monitor post-disaster recovery over time with three state-of-the-art DL models: Vision Transformer (ViT), ConvNeXt, and MaxViT for PDDRM classification across four key recovery states: Not Damaged, Not Recovered, Recovered, and New Buildings. To generate super-resolution (SR) images, LR images were first paired with HR images to train ESRGAN. Numerical evaluations using Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index Measure (SSIM) between SR and HR images confirm that ESRGAN effectively reconstructs high-resolution features, with Not Damaged (PSNR: 29.2, SSIM: 0.78) and New Buildings (PSNR: 30.3, SSIM: 0.81) exhibiting the highest reconstruction quality. ESRGAN-generated SR images were then compared against LR images in terms of classification accuracy and reliability. The results demonstrate that SR improves classification accuracy and precision, particularly for ViT and ConvNeXt, with ViT achieving an accuracy of 84\% and ConvNeXt 82\% on SR images, compared to 79\% and 78\% on LR images. We also employed Grad-CAM++ visualizations to interpret model predictions, which highlighted reliability improvements in certain classes. This study demonstrates that SR is a scalable and cost-effective alternative to very high-resolution satellite imagery, reducing dependency on expensive data sources while improving classification accuracy for PDDRM.},
  langid = {english},
  keywords = {Class imbalance mitigation,Enhanced Super-Resolution Generative Adversarial Networks (ESRGAN),Post-disaster damage detection and recovery monitoring,Remote sensing},
  file = {/home/james/snap/zotero-snap/common/Zotero/storage/YMFBBLXP/Lagap and Ghaffarian - 2025 - Enhancing Post-Disaster Damage Detection and Recovery Monitoring by Addressing Class Imbalance in Sa.pdf}
}

@article{teohExploringGenerativeAI2024,
  title = {Exploring {{Generative AI}} for {{YOLO-Based Object Detection}} to {{Enhance Flood Disaster Response}} in {{Malaysia}}},
  author = {Teoh, Jiehan and Zulkoffli, Zuliani Binti and Yap, Kian Meng and Chua, Huang Shen},
  year = {2024},
  journal = {IEEE Access},
  volume = {12},
  pages = {173686--173699},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2024.3498893},
  urldate = {2025-09-04},
  abstract = {F lood disasters pose significant threats to communities around the world. In Malaysia, floods are recurrent and severe natural disasters due to its geographical location. Focusing on the response phase of flood disaster management, this study identifies the critical issues involved, including the limitations of manual observation in traditional methods and the lack of structured flood image databases. This research explores the use of generative artificial intelligence (gen-AI) to create synthetic images as an alternative source in flood disaster detection and response. By adopting a systematic approach with the You Only Look Once (YOLO) algorithm, the model is trained on gen-AI-produced synthetic images and tested using real drone-captured images from past flood events. The model demonstrates promising preliminary results with the highest performing model, achieving a mean average precision (mAP50) of 96.7\%, mAP@[0.5,0.95] of 78.7\% and an F1 score of 90.8\%. These findings highlight the potential of gen-AI in supporting flood disaster response efforts in Malaysia, aiming to integrate the mix of synthetic images during non-flooding periods and actual drone images during flood scenarios into the comprehensive FloodIntel framework for future research.},
  keywords = {Artificial intelligence,Artificial intelligence (AI),Data collection,Data models,Disasters,drones,Drones,flood,flood disaster management,flood disaster response,FloodIntel,Floods,Generative AI,generative AI (gen-AI),Malaysia,Satellites,Solid modeling,synthetic image,Training,You Only Look Once (YOLO)},
  file = {/home/james/snap/zotero-snap/common/Zotero/storage/4RWVAR7I/Teoh et al. - 2024 - Exploring Generative AI for YOLO-Based Object Detection to Enhance Flood Disaster Response in Malays.pdf}
}
